[00:00 - 00:05]  All right.

[00:05 - 00:06]  I think we're alive.

[00:06 - 00:10]  I'm gonna wait for it to show off on my other monitor here before I get started just to make

[00:10 - 00:14]  sure we're good to go.

[00:14 - 00:16]  But I think we're good.

[00:16 - 00:18]  Okay, nice, there we go.

[00:18 - 00:19]  Now I got the confirmation.

[00:19 - 00:22]  I have to wait for the delay myself to make sure we're good.

[00:22 - 00:25]  It's been a bit since I've done a live stream now.

[00:25 - 01:25]  Probably, let's see, I think August, halfway through August was the first or the last time, so it's been about a month and a half now, almost. So yeah, welcome everyone to the next live stream here, doing a live AI agent build. It's something that I've never done before. I did something kind of similar with N8N, like way back in December of last year, built an agent live, but like that wasn't nearly as complete as what I hope to do with you all in this stream today. So I'm really looking forward to this. Before we really get into stuff, I'm going to give a couple of minutes for people to join and then also just chat with you guys a little bit and talk about what's what's up with the stream for today. So yeah, on my right-hand monitor, that's where I'll have like any support materials I need to like look at as I'm building. Left monitors where I'll have the chat. So if you see me looking around, that's just because I'm looking at my other monitors here. But yeah, I've got the chat open up on my left-hand window and I've

[01:25 - 01:29]  done this before and all my other live streams in the past at any point I can click

[01:29 - 02:13]  on anything any message and then I can see it. So I guess I'll just swap to this now. So you guys can see my screen. I didn't have it configured for when it was like just my face but yeah so you can see that I

[02:13 - 02:18]  can select any message here and then I can display it so for any questions that

[02:18 - 02:21]  we've got I can like have it pop up on the screen as I'm answering it so

[02:21 - 02:26]  everyone knows what I'm talking about exactly so yeah all right that's that's

[02:26 - 02:32]  how things are gonna roll here huge Marley said join Dynamist it's amazing I

[02:32 - 03:32]  appreciate that very much means a lot ever looked into AI for video analysis. Is it any good? That's a good question. I have not, actually. And video analysis can mean a lot of different things. If you mean analyzing it frame by frame for something, like to give you feedback or to look for like copyright material. I haven't done that before. But I know that YouTube does a lot of that under the hood actually. So yeah, great, looks good. Okay, glad to hear it. Yeah, and I'll go ahead and clear this now. Okay, cool. So, yeah, how many people we got in this stream right now? We got 124 watching live. Okay, sweet. I appreciate that. So thank you, everyone, for being here. I'm really excited for the stream today. So we're going to build a full AI agent. I want this to be super practical and educational, but at the same time, I want it to be rather casual. We're just going to have a good time. And I'm building something from scratch, which, spoiler, it does mean that I'm going probably fumble in a couple of parts as

[03:32 - 03:37]  we're going through the build it's not gonna be extremely smooth like when I

[03:37 - 03:40]  show building an agent in a YouTube video and for anyone that's in the

[03:40 - 03:44]  dynamist community you know what I'm talking about when I do the live builds

[03:44 - 03:48]  there that it and it's kind of like actually educational in its own right to see

[03:48 - 03:51]  me mess up on things and have to work through issues but it's the kind of thing

[03:51 - 03:55]  that we don't have in a YouTube video so yeah and then throughout the

[03:55 - 04:49]  stream I'm gonna really try to remember to drink some water because otherwise I get my voice gets really hoarse halfway through. So can't forget to do that. So yeah. So another thing that I want to say is that throughout the process here of building our AI agent, which we'll get into in just a second here, and this is the agent that we're going to be building. And maybe you saw this diagram if you saw my little teaser announcement on Friday for our stream today. I'm going to be going through an AI coding process that I have started to cover in a new agentic coding course that I've released in Dynamis. And so I'm just going to mention the course a couple of times through the live stream. I think you guys will find that fair. I just launched the first part of this course on Friday. And so I just want to call it out a couple of times, especially how it relates to some of the concepts

[04:49 - 04:52]  that I'm showing you all during this stream

[04:52 - 04:53]  as we build an agent together.

[04:53 - 04:56]  So I'm not going to go into a ton of detail

[04:56 - 04:59]  on every part of our development workflow

[04:59 - 05:00]  with AI coding assistance.

[05:00 - 05:03]  But if you want a lot of detail,

[05:03 - 05:05]  and you really want to learn what it looks like

[05:05 - 05:07]  to build your own reliable and repeatable systems

[05:07 - 05:10]  for getting insane results with AI coding assistance,

[05:10 - 05:13]  then definitely check out dynamist.aI.

[05:13 - 05:40]  And the last thing I'll say on this before we get right into building the agent, and I'll put this in the chat as well. And then I'll also highlight it here. So you can see it. If you sign up for the community during this live stream, this is only going to be available while the live stream is going on. I've got a special discount for you guys, for both the monthly and yearly memberships of Dynamis. So you just go to dynamist.AI. I'll show you the site right now.

[05:40 - 05:42]  You just go to dynamist.a.i.

[05:42 - 05:44]  And you can join the community.

[05:44 - 05:49]  It's currently a 10% discount and 25% discount

[05:49 - 05:51]  for anyone joining right now.

[05:51 - 05:55]  But for you guys, it's now gonna be 20% for annual

[05:55 - 05:58]  or for monthly and then 40% off for annual.

[05:58 - 06:00]  If you join during this live stream.

[06:00 - 06:03]  And hopefully as we go through building the agent today,

[06:03 - 06:07]  and I talk about like how I dive deeper into certain things

[06:07 - 06:10]  within the new agentic coding course that's being released,

[06:10 - 06:11]  that'll pique your interest.

[06:11 - 06:13]  That's the, it's like, you know, kind of a side goal

[06:13 - 06:15]  that I have for you in this stream here.

[06:15 - 06:18]  But of course, the primary goal is to give you guys

[06:18 - 06:21]  a ton of value building this agent live.

[06:21 - 06:25]  So yeah, I'll go ahead and so like this message

[06:25 - 06:27]  that I have up right here, I'll share that once in a while

[06:27 - 06:29]  throughout the stream just to give you guys

[06:29 - 06:31]  the opportunity if you're interested.

[06:31 - 06:36]  But yeah, I'll go ahead and take that down right now and oh yeah we'll just

[06:36 - 06:40]  show it later on so okay cool Joe said it's great already diving into the new

[06:40 - 06:43]  course cool I appreciate it Joe yeah we got a lot of people in the community

[06:43 - 06:49]  that are already diving in excited about it so yeah that means a lot yeah one more

[06:49 - 06:53]  question I'll answer quick how is your course for non-programmers yeah and then I

[06:53 - 06:57]  really appreciate you asking this so the course is designed it's made for

[06:57 - 07:25]  beginners but designed for mastery. And what I mean by that is like you can jump in even if you don't have programming experience. And I talk about how you can use AI coding assistance, not just to write the code, but also to help you understand concepts and even like help you install the things that you need for the course, like Git, for example, or your IDE. So yeah, but then also like we go pretty deep throughout the course as well, like really advanced concepts if you want to, you know, truly being like the top 5% and beyond of people

[07:25 - 07:28]  that are building these systems around AI coding assistance.

[07:28 - 07:32]  So yeah, cool, I appreciate that a lot, Sebastian.

[07:32 - 07:33]  Thank you.

[07:33 - 07:36]  Yeah, so with that, let's go ahead now

[07:36 - 07:40]  and get into building our agent.

[07:40 - 07:42]  And I'm really excited for this,

[07:42 - 07:46]  because I've honestly wanted to create this AI agent

[07:46 - 08:20]  for my channel for a long time now. And I haven't gotten around to it just because there's a lot that goes into really refining this agent and productionizing it for all of you. Like we're not gonna finish finish it in this stream, but we're gonna get a really good starting point. And I've just been so busy with other content that I'm creating on YouTube and everything I'm doing a dynamist. But now it is the time to build this agent. It is a personal AI coach for both AI agents and AI coding. And so the end results, and hopefully what we can get to in this live stream,

[08:21 - 08:28]  is to have a chat interface that looks kind of like this. So it's kind of like a chat GPT-style

[08:28 - 08:32]  interface that you sign into. We'll have SuperBase authentication under the hood. I want to build

[08:32 - 08:39]  that as well. And you can talk to this agent. Like I can say, what is the latest news on

[08:39 - 08:42]  Claude Code? Or I could say Claude Skills or whatever, right?

[08:42 - 08:45]  Like asking it questions just like you would chat, GPT,

[08:45 - 08:48]  but under the hood, it's going to be an advanced RAG agent

[08:48 - 08:52]  that is trained on all of my YouTube content.

[08:52 - 08:54]  And then later on, I want to include a lot of other things as well,

[08:54 - 08:57]  like open source repositories that I'm working on,

[08:57 - 08:59]  any articles that I want to share.

[08:59 - 09:01]  Like if I'm researching things and I'm like,

[09:01 - 09:03]  oh, this is like so good to include in the agent,

[09:03 - 09:05]  then I can just like dump it in in the rag pipeline.

[09:05 - 09:07]  We'll pick it up and include it right in the knowledge.

[09:48 - 10:03]  So because like the two things I focus on are building agents and using AI coding assistance, that's kind of going to be like what the agent is an expert in, right? So like trained on all of my knowledge and using advanced rag techniques to make it really accurate and precise. And so this chat interface that you're looking at right here is the one that I build in the Dynamis AI agent mastery course. And so we'll be using this and building the agent today in a way where like with the back end for the agent it can like plug right into this front end so I really do hope to have like a full sack application for the agent by the end of our stream today and we'll be using a few different technologies to get the job done here obviously YouTube we're going to be pulling all of our all of my YouTube videos for the rag pipeline so that's going to be our knowledge source for our agent to start things off we'll be using Pidentic AI to build our AI agent in Python.

[10:04 - 10:07]  Superbase will be our database, because I also want to use that for authentication.

[10:09 - 10:13]  And then last but not least, I want to leverage Dockling, which I covered on my channel

[10:13 - 10:13]  recently.

[10:13 - 10:19]  It's a rag library that helps with data extraction from different file types, and then also

[10:19 - 10:22]  a couple of chunking strategies that they give us.

[10:22 - 10:54]  So a way to take all of our, in this case, YouTube transcripts and find a way to split them up into different chunks so that we can insert information efficiently into our knowledge base. So we'll be using a strategy for chunking called hybrid chunking, which I'm really excited to incorporate Dockling for this specifically, because hybrid chunking is one of the things that has, like, seriously leveled up my rag game recently. I've been trying a lot of other strategies before, even some more, like like custom chunking ones and nothing has worked as well as

[10:54 - 11:00]  this like it's actually insane so we'll get to that actually towards the start of the stream

[11:00 - 11:07]  because we will be building the rag pipeline first and so this stream pretty pretty simply is going

[11:07 - 11:12]  to be like let's build the rag pipeline for our YouTube data and using dockling and storing things

[11:12 - 11:22]  in super base and then we will build our agent with pedantic AI so it it's gonna be kind of two loops of using the AI coding assistant

[11:22 - 11:25]  process that I'll cover with you guys here.

[11:25 - 11:27]  So this is one of the things that I get into

[11:27 - 11:30]  in a lot more detail in the Agenic coding course.

[11:30 - 11:35]  But my typical process for working with AI coding assistance

[11:35 - 11:40]  is I go through this mental model of planning,

[11:40 - 11:42]  then implementing, then validating,

[11:42 - 11:43]  and then kind of doing that in a loop

[11:43 - 11:45]  for all the features that I want in my code base.

[11:45 - 11:48]  And so like for example, when we build the RAG pipeline

[11:48 - 11:52]  to bring in YouTube content into our Supa-based knowledge base,

[11:52 - 11:55]  that's gonna be one iteration of planning,

[11:55 - 11:57]  then implementing and validating.

[11:57 - 11:58]  And that's what we're gonna do together in this stream,

[11:58 - 12:02]  is I'll go through my process of exploring my tech stack

[12:02 - 12:05]  and architecture, really defining things at a high level

[12:05 - 12:09]  with just a very unstructured conversation with ourselves

[12:09 - 12:12]  and then the AI coding assistant as well.

[12:12 - 12:17]  And then I'll show you what that looks like transitioning into a very structured plan,

[12:17 - 12:22]  where we're outlining a complete plan of attack for our coding assistant with things like

[12:22 - 12:27]  goals and success criteria, the task list that we're going to be integrating with ARCON,

[12:27 - 12:29]  a lot of fun stuff in store for that, right?

[12:29 - 12:31]  And so that's our planning phase.

[12:31 - 12:35]  And then once we have our structured plan, we'll implement that.

[12:35 - 13:03]  And this is where we really delegate all the coding to the AI coding assistant, and then we just verify things ourselves in the last phase, the validation phase. So that really is the loop that we have here that I'm covering in this stream. And then when we iterate, that would be like for us, like once we're done with the RAG pipeline, then we'll go through planning, implementing, and validating again, this time for the AI agent. Right. So like where there's the two core parts to the application that we're building together. And we're going to do the PIV loop, as I like to call it, right?

[13:03 - 13:07]  Like P-I-V, we'll do the P-V-Loop for each of those parts.

[13:08 - 13:09]  So that's the plan.

[13:10 - 13:13]  And, yeah, I'm going to try to make this kind of interactive as well.

[13:13 - 13:18]  So maybe I'll, like, ask you guys some questions just as I am going through things.

[13:19 - 13:22]  Like, for example, as we're going through the planning here,

[13:22 - 13:27]  there's definitely, like, a lot of considerations we need to think through up front for our Ragn pipeline.

[13:27 - 13:54]  Like, how do we want to ingest our YouTube information? Like, do we care about getting timestamps or do we not want that? Right, there's those little decisions that's actually really important to make up front because really the goal of the planning phase. And this is like one of the most important things I want you guys to get out of this live stream and because this applies to building this rag agent applies to building really anything. One of the primary goals of the planning phase is to in your structure plan, hear me out on this, in your structure plan, hear me out on this,

[13:54 - 13:57]  in your structure plan, you want to reduce

[13:57 - 14:01]  the number of assumptions your AI coding assistant

[14:01 - 14:05]  is making an implementation as much as possible.

[14:05 - 14:06]  And so that's why it's so important for us

[14:06 - 14:09]  to spend time upfront planning and thinking through

[14:09 - 14:11]  even all the little things.

[14:11 - 14:14]  And so that's what I wanna cover with you guys first.

[14:14 - 14:17]  And so before we even get into our AI coding assistant,

[14:17 - 14:18]  which we'll do that in a sec,

[14:18 - 14:49]  I wanna just do like a little bit of scratch pad planning with you guys. And I think this is like one of those things that I don't cover enough on my channel because it definitely fits a live stream format to do this kind of thing much better. And so we'll just plan some things together. And I'll ask you guys some questions about, you know, like the things that we should consider as we're building this agent and making it interactive in that way as well. And yeah, I saw the question what tools this thanks Mike for giving the

[14:49 - 14:54]  answer as well this is Excaladra that I have as a plug-in integrated directly within

[14:54 - 15:00]  Obsidian so Obsidian is a free and local note-taking and knowledge management

[15:00 - 15:03]  platform that I've started to transition a lot of things to I was using a lot of

[15:03 - 15:08]  like Google Drive and Asana and stuff before absolutely loving it and then

[15:08 - 15:12]  Excaladra is a tool that lives outside of Obsidian as well,

[15:12 - 15:14]  but I have a plugin that brings it directly in here.

[15:14 - 15:18]  So I can add obsidian, or excuse me,

[15:18 - 15:21]  I can add Excaladra diagrams and things

[15:21 - 15:23]  like directly within all my other notes and documents

[15:23 - 15:26]  and even have these diagrams reference

[15:26 - 15:28]  all of my notes and knowledge and vice versa.

[15:28 - 15:29]  That's pretty cool.

[15:32 - 15:36]  So yeah, and then the laser pointer, I just press K,

[15:36 - 15:37]  like that's my hot key.

[15:37 - 15:42]  And then I have this super cool laser pointer um that uh yeah i've

[15:42 - 15:47]  started to use this like all the time like if you go and you take the agenta coding course that i

[15:47 - 15:52]  have in dynamist now you'll see me use this a lot just as i explain things like the piv loop for example

[15:53 - 16:00]  so all right so we're going to go i'm going to go to white text here piv loop number one is going to be

[16:00 - 16:59]  our rag pipeline all right and then piv loop number two is going to be our rag agent so let's kind of uh let's zoom out before we even get into the a i coding assistant i really want to zoom out here and plan things with you guys because this is what building real software looks like you you need to spend time doing this kind of thing before you get into the actual coding um so i'm actually really excited to do this with you guys so all right pivot loop number one we've got ourG pipeline and I'll just kind of like show off what you can do in Excalada draw, just like making things look kind of nice here. So, all right, we've got our two PIV loops. And so for our RAG pipeline specifically, I just want to think through like what are the things that we should consider before we even talk to the AI coding assistant of what we want to build. So we are building a YouTube video rag pipeline. Okay. And what's what should our tech stack be right like what tools should we even consider using?

[16:59 - 17:05]  Well first of all I mean this part I kind of already have to find right like I thought of this definitely ahead of time

[17:05 - 17:08]  we're gonna be building some things from scratch for like right now I know that I want to use Python

[17:10 - 17:12]  for my programming language for the pipeline

[17:13 - 17:17]  specifically the tool that I'm gonna be using to get YouTube transcripts

[17:18 - 17:22]  I'm gonna use something called super data I've used this in the past.

[17:22 - 17:25]  It's not free, but it's really cheap.

[17:25 - 17:27]  Because if you don't use a service like this

[17:27 - 17:29]  to get YouTube transcripts,

[17:29 - 17:32]  then you risk hitting a lot of rate limits and IP blockings

[17:32 - 17:34]  and things like that.

[17:34 - 17:36]  And so, yeah, let me go to the homepage here,

[17:36 - 17:39]  just so you can see, oh, I spelled it wrong.

[17:39 - 17:41]  All right, supadeta.aI, there we go.

[17:41 - 17:43]  And this works for more than just YouTube, by the way,

[17:43 - 17:46]  and you get your first 100 requests for free.

[17:46 - 18:42]  So I debated a lot, like, should I use SuperData or should I just use the YouTube API directly? Because the YouTube API would be free. But the problem is, and like, this is really annoying because, like, I hate having to pay for something just to get YouTube transcripts. But, like, in the end, I think this is so worth it. Because the YouTube API, you're only able to get the transcripts for videos that you have edit permission on. So basically your own videos, right? And like, that's fine for what I'm building here with this agent. But like, what if I wanted to extend this so that, like, we could take in anyone else's YouTube channel. Like, I could go grab Network Chuck's videos. And then we got an agent that's trained on Network Chuck, or I go grab, like, reendorse. And then we got, like, an AI coach that's trained on reendorses YouTube content. Like, we could do that. And I think that'd be so cool. So I don't want to limit myself to my own videos and so that's why I'm

[18:42 - 18:47]  using SuperData here. And you just like grab an API key. I'm paying like I think like $10 a

[18:47 - 18:51]  month for SuperData. It's super cheap. And so that I mean really like a thousand videos being

[18:51 - 18:58]  pulled a month is all I need. So yeah, that's going to be our tech stack here. And then like

[18:58 - 19:03]  other considerations that we need to think through. Other considerations. And this is where I want

[19:03 - 19:59]  you guys to give some suggestions here. So I'll be looking in the chat at the same time that I'm typing stuff out. But this is where we need to think about like how should we pull data from YouTube and then how do we want to store that, right? For example, I'll just give you guys an example here. We don't want to pull videos older than a week. Let's just like consider that one of our constraints. Because this rag pipeline, I want it to run on a scheduled basis, right? Like every day or every hour, it's going to run and check for new YouTube videos in a channel that I specify. And maybe, let's say, we'll specify the channel ID in an environment variable, right? So, like, we'll make us a, like, this instance of the RAG pipeline is monitoring a single YouTube channel. And then if we wanted to, like, duplicate this AI coach for another YouTube channel, we just have another instance of the application running, for example.

[19:59 - 20:02]  I think that's the best way to keep it simple right now.

[20:04 - 20:10]  And then, let's see, Joseph said using Langraph as a tech stack, we could incorporate Langraph,

[20:11 - 20:14]  though I think to keep things simple right now, I'll stick with just Pidentic AI.

[20:15 - 20:21]  My general philosophy is that once an application or like an agent gets too complex for a single

[20:21 - 20:25]  AI agent, that's when I'll expand to multi-agent and then at that point I'm using

[20:25 - 20:29]  Langraph very extensively so I appreciate the thought but I definitely want to

[20:29 - 20:36]  keep it simpler here okay I don't want to pull the same video twice 100% yep

[20:36 - 20:44]  so check the database to make sure video isn't processed already very good yeah

[20:44 - 20:48]  I appreciate that idea and really one of the beautiful things that and let me

[20:48 - 20:51]  move this over a little bit so we got room. One of the beautiful things

[20:51 - 20:58]  with YouTube videos is that you can't actually change the content of a video once it's posted.

[20:59 - 21:04]  And so we are guaranteed that if the video is already in the database, we don't ever have a need

[21:04 - 21:10]  to update it. Right? Because like if you want to change a video, you literally have to delete it

[21:10 - 21:14]  and re-upload it. And no one really does that. I don't even think that's an edge case that I have

[21:14 - 21:18]  to really cover in this application unless I like really want to make it robust

[21:18 - 21:24]  later on filter conditions are needed and a trigger yeah exactly so I have to think about

[21:24 - 21:37]  think about how to trigger this application filtering for videos well I mean that kind of is what I

[21:37 - 21:41]  have here we don't want to pull videos older than a week I think that's really the only filter

[21:41 - 23:01]  that we need and then obviously making sure that they aren't already processed so those are kind of like the two filters that we have here so that's good and like every single one of the things that we're defining here is removing an assumption of the AI coding assistant if we didn't specify a week then maybe you would think two months and then we pull in way too many transcripts to process at once and that would just be a waste of our super data credits for example right like these are the things that we don't want our coding assistant to assume if the transcript fails retry that's a good thought if the transcript fails retry and we'll say like retry once like just give it one more shot otherwise otherwise give an error I don't know exactly what that would look like we'll probably have some monitoring set up at some point for this application why super data over appify that's a good question I just super data works really well for me it's super convenient and cheap i don't really know like apify pricing i haven't used appify for a while i'm going to be honest it probably is a solution that would uh work just as well as super data youtube scraper honestly this probably would work well too i'm just going to use super data because that's what i am familiar with and i just i know i'm'm gonna be able to validate the code

[23:01 - 23:03]  that's outputted a lot better using SuperData,

[23:03 - 23:05]  but yeah, Appify would be another good option.

[23:05 - 23:06]  I think that like in the end,

[23:06 - 23:08]  the exact tool that we're using

[23:08 - 23:11]  to get the YouTube data is not extremely important

[23:11 - 23:12]  for what we're building.

[23:12 - 23:14]  And honestly, I think it'd be very easy

[23:14 - 23:16]  to swap this out at any point

[23:16 - 23:18]  because it's only gonna be a few simple API calls

[23:18 - 23:20]  to get the actual YouTube data.

[23:20 - 23:23]  Most of the work is gonna go into building

[23:23 - 23:24]  the rest of the rag pipeline,

[23:24 - 24:18]  like chunking and storing things in our knowledge base, and then also building the agent itself. But, yeah, Appify is probably fantastic as well. So, yeah, I'm going back here. Joseph said, text stack, century. It's a good thought. Monitoring slash observability for the agent. I would say, though, that Joseph, the tech stack for observability is going to come for the second Pibloop. So I'm going to actually hold off here. Well, I guess that's fair. We might want to do Century for the Rag Pipeline. And then maybe like an agent-specific one, like Langfuse for the agent. I'm going to say like for the Rag Pipeline, though, I just want to keep it simple right now. But I do definitely want to add in a monitoring solution for the agent itself. And then maybe later for the pipeline as well. Is it guaranteed to have a transcript of this API. I believe it is.

[24:18 - 24:20]  Yep.

[24:20 - 24:46]  Will you add web search capabilities as well and then expand the knowledge base to enhance the YouTube knowledge base? Yeah, so later on I do want to do that. Right now, though I want to stick with just YouTube to make it simple at first. Because it's always important to build in iterations, right? Like you could just try to include all of the different data sources, right? Like I could right now try to build in articles and I could try to build in YouTube content like we're doing right now.

[24:46 - 24:50]  I could do open source repos. I could give it web search and give it the ability to do

[24:50 - 24:54]  like deep research and build its own knowledge base. Like I could try to do all of those things,

[24:54 - 25:00]  but that's going to get so messy for the coding assistant up front that I would 100% want to do that

[25:00 - 25:05]  in another PIV loop. Like maybe later on, I'll go ahead and copy this just to make this nice

[25:05 - 26:04]  and visual for you guys. Like maybe like a PIV loop number three is going to be deep research. I don't know, maybe, something like that, or just like some other knowledge source. And then maybe PIV loop number four is we're gonna do, let's say, agent observability, agent observability. All right, for some reason that's a hard word for me to type out sometimes. All right, right, right, like we can keep iterating on the agent just as we wanna keep adding more features. And so we want to start pretty simple. Like in this case, it's a rag pipeline, just YouTube videos. That's it. Make it nice and simple. Something that is kind of more of an MVP, like a proof of concept. We get the pipeline working. Hopefully we design it in a way where it's easy to add other sources. So actually that could be another consideration here. Make it easy to add other data sources in the future besides YouTube, right? So like building it intelligently like in a very

[26:04 - 26:09]  considerable it's considerate way up front is very important so it's good that we're

[26:09 - 26:13]  having this conversation just so that we can think about these these

[26:13 - 26:17]  assumptions that we want to take away or the instructions that we want to give to our

[26:17 - 26:25]  coding assistant time stamps yes or no what metadata chunking size very good Toby I

[26:25 - 28:13]  agree 100% so yeah let's say that we don't care about timestamps. Well, actually, you know what? I think we do. Because if we want to cite a source, then we could also like even cite to like the exact time in the YouTube video to go to, or like the chunk of time that that text comes in. So we can say metadata, including video URL, timestamp for the chunk. I hope that is available to us. I don't actually know for sure. But I think those would be the main things. And then we could just say like channel ID as well. I suppose that would be useful. Let's see. Chunking size. Chunking size doesn't really apply here actually because we are using hybrid chunking. So really what we're defining is going to be the minimum and maximum chunk size versus like an explicit size. And so we'll say that min chunk is going to be let's do 400 characters max chunk or let's just say min 400 characters max will do a thousand characters i think that'll be a pretty good number and then we could always set those environment as environment variables so set the min and max chunk as environment variables as as well. So there we can make that one of the things that's configurable as well as the channel ID so we want to like think about the things that we want to be able to define and config versus the things that are just like sitting there in code like I generally don't want something like this to be hard-coded in the code somewhere so yeah Sean said okay yeah so Sean let me go ahead and put up your message here because this is good to to know.

[28:17 - 28:17]  Yep, so, yeah, Dynamis 20 is 20% off monthly.

[28:19 - 28:20]  Dynamous 40 is 40% off yearly.

[28:24 - 28:28]  And then Sean said that Dynamis 40 only shows as 20% off. The reason for that, Sean, is because there's already a discount for the early adopters,

[28:28 - 28:29]  like outside of this live stream.

[28:30 - 28:31]  So it's a discount on a discount.

[28:32 - 28:35]  I know it's a little bit confusing, but it is for the yearly.

[28:35 - 28:40]  It's going to be 40% off the full annual price for joining the community.

[28:40 - 28:41]  I hope that clears that up.

[28:41 - 28:44]  I just wanted to address that really quick

[28:44 - 28:48]  before we go on to the next part of building this agent here.

[28:48 - 28:51]  Because yeah, I think at this point,

[28:51 - 28:53]  I'm pretty confident with the planning

[28:53 - 28:54]  that I've done here with you guys.

[28:54 - 28:57]  And I appreciate all of your suggestions, by the way.

[28:57 - 28:59]  Like, thank you for helping me think about everything

[28:59 - 28:59]  that we want.

[28:59 - 29:08]  Because now with this, we can dive right into our implementation. And so I've got the repository open in my editor here and I'm working

[29:08 - 29:14]  from a blank slate today. The only thing that I have done and I'll kind of show you guys this

[29:14 - 29:20]  really briefly is I've set up what I like to call my AI layer. So I have things like my commands,

[29:20 - 29:26]  my reusable prompts. I have some examples that I wanted to reference from previous work that I've

[29:26 - 30:49]  done. And I would highly, highly recommend doing this. This is one of the things that I actually call out in the PIV loop. When you are working on a brand new project, generally the things that you're researching with the help of your AI coding assistant is online resources, like how did other people build a similar application and what does their tech stack look like, but then also previous projects that you've worked on. It's kind of, it's like one of the biggest cheat codes when using AI coding assistants. When you have been building AI agents for a while, like I have, obviously, you start to build this big collection of past projects that are at least one of them is going to probably be pretty similar to what you're creating right now. And so it's a huge cheat code because during the planning phase and even the implementation phase, you'll have your AI coding assistant constantly reference to the examples that you have prepared for it so that it knows how to do things like set up the agent how to define tools well how to configure observability with langfuse for example and like i literally have all of these things ready for it to go um so that i can like tell it as a part of the structure plan that i create like here's where you go um so that you know how to create an API endpoint around the agent so we can use it in the the front end that we have to find right here Like I said, we're gonna integrate it directly

[30:49 - 30:50]  into this front end.

[30:50 - 30:51]  And the way that the coding assistant

[30:51 - 30:53]  is gonna be able to do that very easily

[30:53 - 30:56]  is it can look at the example that I have pasted in here.

[30:56 - 30:57]  This is my cheap code.

[30:57 - 31:00]  I made an API endpoint around my agent before.

[31:00 - 31:03]  I'm gonna do it exactly the same way again.

[31:03 - 31:05]  As long as this implementation is good,

[31:05 - 31:09]  and I made it good, then we can just reuse the heck out of it

[31:09 - 31:11]  for all the agents that you wanna integrate

[31:11 - 31:16]  into a full stack application going forward. And by the the way everything that I have in the

[31:16 - 31:21]  examples folder here I also have in the repo that I will share with you guys

[31:21 - 31:25]  right now so this like initial AI layer that has my commands and examples and

[31:25 - 31:32]  everything I have this push to a public repo that I will share in the chat right

[31:32 - 31:38]  now so there's a link to it if you guys are interested in pulling this and I

[31:38 - 31:41]  mean you could follow along right now if you want to.

[31:41 - 31:44]  You could just use this as a resource to see kind of how I've set up my AI layer,

[31:45 - 31:47]  like taking a look at the different commands that I have.

[31:48 - 31:53]  The three core commands that are going to be guiding my PIV loop, as I'm calling it,

[31:54 - 31:56]  I have one called the Primer.

[31:57 - 32:02]  And the primer is not, I'm not going to use this right away.

[32:02 - 32:04]  It's more from when you're working on an existing code base.

[32:04 - 32:39]  You use this command to instruct the coding assistant on how to analyze your code base to kind of like catch it up to speed so you start a brand new conversation with your coding assistant and then it can prime itself on your code base so it now understands how your code works so that you can go and implement a new feature right so we'll use this later on this is a very power like I I I I'm working on an existing code base I will literally always start a conversation with a priming command like every single time and then we'll use the create plan to create that structured plan once we kind

[32:39 - 32:44]  of have the initial detail set with the AI coding assistant and then when we go into the

[32:44 - 32:50]  implementation plan we will use the execute command slash command so I will show you all of this in

[32:50 - 32:55]  action to make it really concrete for you and again these are some of the things that I dive into

[32:55 - 32:59]  in a lot more detail in the agented coding course.

[32:59 - 33:02]  Like not only how these commands work,

[33:02 - 33:04]  but literally how you can build your own

[33:04 - 33:06]  to start to define your own system

[33:06 - 33:08]  for working with coding assistance.

[33:08 - 33:09]  Because in the end, there are a lot of things

[33:09 - 33:11]  that you can just like take us templates for me

[33:11 - 33:14]  or other things like the B-Mad method, for example,

[33:14 - 33:16]  but the true power comes in when you can design a system

[33:16 - 33:18]  that's optimized for your code base.

[33:18 - 33:20]  And that's what I teach you how to do.

[33:21 - 33:25]  So yeah, with that, let's open up a conversation here.

[33:26 - 33:27]  Let's chat with our coding system.

[33:27 - 33:31]  So I'm going to be using Claude Code in the stream for today.

[33:32 - 33:36]  But everything that I cover here, man, you could use any AI coding system you want.

[33:36 - 33:41]  Because literally, like all the commands that I have here, like to create a plan, for example.

[33:41 - 33:46]  I know that in Claude code is very nice that I can just do like create dash plan, right?

[33:46 - 33:51]  But if you're using something like, I don't know, GitHub copilot that doesn't support slash commands.

[33:51 - 33:56]  All you have to do is say, you know, look at dot clod slash commands slash create plan.

[33:56 - 34:01] md and use this as your instructions right now.

[34:02 - 34:05]  Right, like you can, because all a command is is a prompt, right?

[34:05 - 34:08]  So you just tell it to look at the prompt and execute the prompt,

[34:08 - 34:12]  and then it doesn't even matter that you don't have the idea of a, you know,

[34:12 - 34:13]  slash command.

[34:13 - 34:46]  You can still use the instruction set here. And so to kick things off, I'm going to go into my obsidian diagram here, and I'm going to copy this. So all the planning that we did, I'm not just doing this for theoretical reasons. Like we listed out all these considerations together, and this is going to be part of the context initially when I build the rag pipeline. And so I can paste this in as some extra context here. So we're building a YouTube

[34:46 - 34:50]  video rag pipeline. Here's our tech stack, Python and SuperData, all of our other considerations.

[34:51 - 34:59]  And then what I want to do before I get into any actual coding is just have a conversation

[34:59 - 35:04]  with the coding assistant. Like at this point, we can keep it super casual. I like to call it

[35:04 - 35:13]  vibe planning. This is the first stage to planning. At this point, we're having an unstructured conversation. All I want to do,

[35:13 - 35:19]  this is what I call my layer two planning. All I want to do is figure out for this rag pipeline,

[35:19 - 35:25]  how do I build it, right? Like, let's just explore the tech stack. Let's explore the architecture.

[35:25 - 35:30]  We'll have, I'll have cloud code like search the web so we can understand supadata, how to use super data.

[35:30 - 36:01]  Right, that we're establishing all that context so that we're then going to use the conversation as a part of the context to build that structure plan. And so I'm going to go into a coding assistant here. I'm using Aqua Voice for text to speech. A lot of you guys have seen me use it before. It's $10 a month. There's also another free version of, or like a similar free thing called Epicenter Whispering. So I highly recommend if you're using coding assistants, like don't type you out your prompts like please it's

[36:01 - 36:07]  saved you so much time if you speak them out instead and so aqua voice is what I use

[36:07 - 36:15]  every single day like literally I I I've spoken 300,000 words into Aqua Voice and

[36:15 - 36:21]  my words per minute is 236 so when I'm using Aqua Voice and I know it's $10 a

[36:21 - 36:25]  month that's why I want to suggest a free and local version as well so check this

[36:25 - 36:55]  out if you're interested I'll put these in the chat as well. So free text to speech and then my text to speech. If you guys just want like another golden nugget of recommendations here, like you, you guys, I'm telling you don't speak or don't type your prompts into AI coding assistance. It is so much better to talk it because watch this. I'll say All right, so I opened up my Aqua Voice here by just double pressing alt.

[36:55 - 36:58]  Well, here I should probably delete that.

[36:58 - 37:02]  I don't actually care to have that text in there.

[37:02 - 37:07]  And I will say, building an AI coach.

[37:07 - 37:11]  It's going to be an agent that is trained on my YouTube data.

[37:11 - 37:17]  Now the first thing that I want to build is a RAG pipeline where I can take all of my YouTube videos,

[37:17 - 37:21]  pull the transcripts from them including timestamps and then I want to

[37:21 - 37:26]  chunk those up and store them in a knowledge base and so my tech stack I'll be

[37:26 - 37:31]  using Python for the rag pipeline I want to use the super data to get the YouTube

[37:31 - 37:35]  transcripts with timestamps so I want you to search the web for super data as well

[37:35 - 37:41]  I also have the documentation for super data pulled into Arcon so I want you to

[37:41 - 38:11]  incorporate Arcon and then for the database, I'm going to be using Supabase. So I want you to also help me think about the database tables that I should create to store the YouTube videos and the abettings and everything. And then I also want to use Dockling for the hybrid chunking strategy. So I want you to search the web so you understand hybrid chunking with Dockling as well. And then also within my PRPs slash examples folder, I have a file called Dockling, Hybrid Chunking.

[38:11 - 38:13]  So I want you to take a look at that.

[38:13 - 38:15]  That's a working example that I already have

[38:15 - 38:19]  for using hybrid chunking with Dockling.

[38:19 - 38:22]  And so given that tech stack and also all the considerations

[38:22 - 38:27]  that I've listed above, I want you to not build,

[38:27 - 38:30]  don't code anything yet, but just help me think through

[38:30 - 38:32]  if there's any other considerations that I'm missing.

[38:32 - 38:35]  And then I want you to give me some different options

[38:35 - 38:36]  for how I can implement

[38:36 - 38:38]  this rag pipeline.

[38:38 - 38:39]  Boom, there we go.

[38:40 - 38:42]  All right, so I'll send this in.

[38:42 - 38:43]  And look at how fast that is.

[38:43 - 38:46]  Like it's blazing fast and extremely accurate.

[38:47 - 38:49]  The only thing that it didn't do very well

[38:49 - 38:52]  is it said PRPs and then it like explicitly wrote out

[38:52 - 38:54]  slash when I want it to reference the file.

[38:54 - 38:56]  So I can just go and like edit that.

[38:56 - 38:59]  So like sometimes I'll go and edit things very briefly,

[38:59 - 39:01]  but otherwise, I mean, I trust this.

[39:01 - 39:02]  I think this is really good.

[39:02 - 39:08]  And again, I am following no structure in this conversation at this point.

[39:08 - 39:11]  Like this is kind of a messy prompt, but that is totally okay.

[39:12 - 39:17]  In fact, one thing I'm going to do really quickly is I'm going to copy this.

[39:18 - 39:21]  I forgot to add an ARCON as my MCP server.

[39:22 - 39:26]  So I want to do that really quickly because one thing that I did to prep for this stream

[39:26 - 39:30]  is I pulled the documentation for SUPA data

[39:30 - 39:31]  into ARCON.

[39:31 - 39:34]  So it has access to all the code examples and things

[39:34 - 39:37]  for how to pull transcripts from the SUPA Data API.

[39:37 - 39:38]  It's really neat.

[39:38 - 39:40]  So I have the documentation for ARCON already,

[39:40 - 39:42]  which I'm not gonna cover ARCON for the sake of time

[39:42 - 39:44]  too much in this live stream,

[39:44 - 39:48]  but it is gonna be part of my coding process here.

[39:48 - 39:50]  So I've got the documentation for SUPA data,

[39:50 - 39:55]  supadda, excuse me, and I literally just pulled their LLMs.

[39:55 - 39:59]  Dot text. So that's the source that I'm using in Arcon. So if you want to follow along,

[40:00 - 40:03]  I'll actually post this here, Supa Data-LLMs.

[40:03 - 40:06]  dot text. I'll put this in the YouTube chat. So if you guys want to

[40:06 - 40:09]  include this documentation in your,

[40:10 - 40:14]  in your Archon, you can crawl that. It will take just a couple of minutes.

[40:14 - 40:18]  It's pretty short. So I got the documentation for Supadeta. I just need to

[40:18 - 40:46]  actually hook Arcon into my Claude code really quick, because I just didn't have it set in this terminal here. So I'll add it. There we go, and Cloud MCP list. Make sure that our connection to Arcon is good. Looking good. Okay, perfect. So now I can go back in to Claude, and then I've got the prompt that I can paste back in here. So, okay, a little bit messier now, but that's okay. So I'm going to go ahead and send us in. And so, yep, we're not coding anything yet, but it's going to search for super data.

[40:47 - 40:50]  It's going to understand Dockling and look at my example.

[40:50 - 40:52]  So we're already using my cheat code, right?

[40:52 - 40:54]  Like this is something else that I already did.

[40:54 - 40:57]  I actually showed this on my channel already,

[40:57 - 41:00]  using hybrid chunking within Dockling.

[41:01 - 41:03]  And so now it'll understand how to use that as well.

[41:03 - 41:07]  So I'm just having it, I'm kind of just like gathering as much context

[41:07 - 41:10]  as I possibly can to make sure that the coding assistant

[41:10 - 41:14]  is on the same page with me for what needs to be implemented and

[41:14 - 41:18]  take a look at that it's searching Arcon as well doing all the web search it's

[41:18 - 41:22]  spelled dockling wrong but that's okay LLMs love to do this all of the time

[41:22 - 41:29]  they will literally spell dockling incorrectly so yeah but I think it'll still get

[41:29 - 41:37]  what it needs so okay in the meantime here don't you need the dockling docks

[41:37 - 41:39]  and Arcon as well?

[41:39 - 41:41]  It probably would help Toby.

[41:41 - 41:47]  The reason that I'm not including the Dockling documentation is because the hybrid chunking

[41:47 - 41:50]  is the only thing that I'm using.

[41:50 - 41:55]  And this example just like lays it out so clearly that I don't really need it to search

[41:55 - 41:57]  anything else within Dockling.

[41:57 - 42:02]  But 100% if I was using a lot more aspects of Dockling, like if I was working with PDF

[42:02 - 42:57]  and Excel extraction, for example, which I might do later for this agent, so I could just dump PDF documents for research that I found and include that in the knowledge base as well. At that point, I would probably include the Dockling Docs in Arcon too. But yeah, I think that's another good lesson is don't over-engineer things, right? Your AI layer, which includes your commands, it includes your global rules that I also have set up for this project already. This is one of the things I created ahead of time. Your AI layer includes all the knowledge that you have in Arcon. Like, don't over-engineer it. If you're only using a tiny part of a library, it might be enough to just include a single example like I did here, or even just to ask it to search the web on something really basic. Now, Arcon is better than web search, because you get to pick what it searches through, right?

[42:57 - 43:00]  But for something really basic, like that is going to be sufficient.

[43:00 - 43:01]  So I would just keep that in mind.

[43:03 - 43:06]  Because then it's just nice that I don't have to, like, go crawl dockling and wait for that.

[43:07 - 43:10]  I mean, maybe it'd be nice to have it anyway, but, yeah, I think you get the point.

[43:13 - 43:16]  Looks like Claw code failed to load the dockling example.

[43:16 - 43:17]  Will it find it?

[43:18 - 43:19]  Oh, is that really true?

[43:20 - 43:21]  Oh, yeah, you're right.

[43:21 - 43:51]  PR. Oh, because it's spelted incorrectly. Interesting. That's actually a problem. I really appreciate you catching that because did you read the, and then I'll call it out explicitly here. So that is one of the warnings that I have with speech to text. It's like sometimes that'll happen where it's not spelled correctly so it misses it. But this was actually really surprising though because generally when Claude Code fails to find a file, it'll try to search for it in a couple of different ways, like using

[43:51 - 43:57]  regex or blob search or something. And so I'm actually surprised I didn't retry. Like that,

[43:57 - 44:02]  that is quite unfortunate. So, yeah, one of those things that you just have to watch out for

[44:02 - 44:05]  as you're having it look through a bunch of files, making sure that it actually spelled things right

[44:05 - 44:10]  and read the file and then retried if it failed for whatever reason. So now I'm having it read it.

[44:10 - 44:21]  So there we go. Okay. Yes. Oh, it said it did read it already, or unless it's saying that, okay, yeah, so it just read it for the first time, because now it's correcting something.

[44:22 - 44:23]  Character-based versus token-based chunking.

[44:26 - 44:28]  It works with tokens, okay, yeah, sure.

[44:28 - 44:29]  All right, so it did correct itself a little bit.

[44:29 - 44:30]  Okay, so good catch.

[44:30 - 44:34]  I appreciate that, Tony, because otherwise it wouldn't have been as good of planning.

[44:37 - 46:00]  Okay, so here we go. Stick with token-based chunking. Uh, yes, let's stick with docklings approach. Um, also give me uh, some options for building this rag pipeline. Okay, so I kind of distracted it a little bit on something really specific, so I'm just going to answer that quickly and then move on to the rest of the questions that it has for me. But at a high level, this is really nice. It did a ton of planning for me already. So a tech stack validation says it's solid. It says Docling and Supubase is great. That's good. I mean, I could ask it more questions so like I can really have it validate if I want, but for the sake of brevity here, I'll just say that like, okay, good, we're on the same page that the tech stack is solid here. And then creating a table for the specific YouTube channels, which I think is nice because it's just going to be my channel to start, but then at some point I might want to go so that this agent could actually pull videos from other channels too. And then pulling YouTube videos in, which I assume that it verified with Super Data that all of these fields are accessible when it pulls the transcript from Super Data. And maybe that's a question that I could ask as well to make sure that it really created this, excuse me, based off of what it can get from SuperData.

[46:02 - 46:07]  And then we have the chunks where we store our individual chunks for the YouTube transcripts,

[46:07 - 46:10]  including when the chunk stops and ends.

[46:10 - 46:12]  So we can cite that as a part of the source.

[46:12 - 46:17]  Like, you know, this piece of information came from my video on Dockling, and you can go

[46:17 - 46:19]  jump to nine minutes in, and then that's where I'll talk about it, right?

[46:20 - 46:21]  That's going to be so cool.

[46:21 - 46:26]  If our AI coach can actually reference like timestamps and videos. That's the goal that I've got here.

[46:52 - 46:57]  Additional considerations. So some of these things I'll probably go through rather quickly just for the sake of time here. But in a real planning, like when you're going through the PIV loop and you want to spend a considerable amount of time making sure you're on the same page with the coding assistant. Like this conversation can go for a solid half hour. It could go for even an hour. If you really want to make sure that like you have the right decisions made around the tech stack that you're considering everything like what's one thing I called out here it says that I'm not considering

[46:57 - 47:04]  API rate limiting and cost management so yeah I mean that's important incremental processing

[47:04 - 47:08]  track the last process at per channel to only fetch new videos that actually makes a lot of

[47:08 - 47:12]  sense so that's one of the things I listed initially that it's getting more specific for me

[47:12 - 47:45]  and so I actually appreciate that a lot and so let's see what it says at the bottom here questions to finalize which option do you prefer i prefer option number four well what are my options option number four detailed recommended pipeline architecture youtube service calls a super data API handles rate limiting and implementing retry logic okay blah blah blah like i said i would spend a lot more time with this normally but i'm gonna just

[47:45 - 47:50]  say that this is good like i'm gonna act like i read through this entire thing and i would recommend

[47:50 - 47:59]  doing that um yeah i don't want it to be considered a tool because at this point this is

[47:59 - 48:04]  just the rag pipeline so okay good i'm gonna say that option number four is good so questions

[48:04 - 48:42]  to finalize uh option four is good and that's where it's going to create a separate folder called YouTube underscore Rag, and it'll build the pipeline there. Token limit, 512 max tokens or different. I'm going to say min should be 400, max should be 1,000, like we established in our diagram. In betting model, stick with AllMMNLM or upgrade to a larger model let's use let's allow to specify the embedding model as an environment variable

[48:45 - 48:55]  so you specify the open a i base URL and embedding model and then again this is my cheat code i already

[48:55 - 49:00]  have a dot enbd example in my example folder.

[49:01 - 49:04]  And so this literally has what I'm talking about here,

[49:04 - 49:05]  where we can set our provider.

[49:05 - 49:08]  Like we want to use OpenAI or Olama or Gemini.

[49:08 - 49:12]  And then we set the embedding base URL and the API key and the model choice.

[49:12 - 49:13]  And so I wanted to look at this.

[49:13 - 49:19]  So I'm going to call out .embe.example to see how this is set up.

[49:20 - 49:22]  And so I'm going to build this AI agent.

[49:22 - 49:55]  This is one of the things that I promised you guys when I was, you know, announcing this, is that it's going to work with any large language model. So I want to make it so that through just configuration, I can go between Gemini, OpenRouter, OpenAI, for both the embedding model and also the large language model that we're using for the agent itself once we get to Pythantic AI. So let's go ahead and do that. And then trigger mechanism, CLI only for now, or do you want an API endpoint? CLI is good. So I just want to be able to call the script that like pulls my YouTube videos. I just

[49:55 - 49:58]  need to do that from the terminal. Like I don't need an API endpoint to do this right now.

[49:59 - 50:04]  And so yeah, I'm going to give it my options here. And so now we're really starting to get

[50:04 - 50:08]  on the same page. Like it's asking me questions to fill in its knowledge gaps. It's telling

[50:08 - 50:14]  me other considerations I need to fill my knowledge gaps. Again, we're just reducing the assumptions

[50:14 - 50:45]  overall. That's 100% the goal that we got here. And so it's going to create a detailed implementation plan here, which I'm going to actually interrupt it and say create plan. I'm going to call, based on our conversation, create a detailed plan for the YouTube Rags pipeline implementation. And so what I'm doing right here is now calling my command that is going to systematically leverage the conversation to do additional research and analyze our tech stack

[50:45 - 50:46]  and architecture and other decisions.

[50:46 - 50:49]  And then it's going to create that structured plan

[50:49 - 50:53]  that I'm talking about within the PIV loop here.

[50:53 - 50:57]  And so now at this point, we are going from Vibe planning,

[50:57 - 51:00]  just a more unstructured conversation,

[51:00 - 51:02]  into our structured plan.

[51:02 - 51:04]  And so we're leveraging the four pillars

[51:04 - 51:06]  of context engineering.

[51:06 - 51:09]  Memory is our conversation that we just had.

[51:09 - 52:28]  Rague is going to be external sources like looking at the supa beta documentation, supa data documentation in ARCON. We're going to define a task list that we're also going to leverage an ARCON. And so we want to split the task up task by tat or split the implementation up task by task so our coding assistant can knock it out in a more systematic approach. And then prompt engineering is really all the techniques we have for outlining the different sections of our structure plan. And so in the command that I have here, one of the things that you'll see is that I outline what the plan looks like, right? Like, we have an overview, what's going to be implemented, a requirement summary, all the documentation we want to reference. Here is our task list, right? Like, this is prompt engineering. This is defining the core sections we want in our structured plan so that we can create a repeatable system or whenever I create the plan, I know exactly what my plan is going to look like, so it's very easy for me to validate it as well. And so there we go. I'm just going to kick this off and have it run. And while it does run, this is another good time for me to just share really quickly the Agenda coding course, because again, all of these things that I'm covering right now, I cover it in a lot more detail in the new Agentic Coding course that just came out.

[52:28 - 52:30]  And I have, okay, I need to do this.

[52:30 - 52:32]  I'm so excited, I didn't even show the page

[52:32 - 52:34]  for the course yet, really.

[52:35 - 52:38]  The first batch, so this course is being released in batches

[52:38 - 52:41]  and like straight into the Dynamist community

[52:41 - 52:42]  over the next month here.

[52:43 - 52:47]  And the first batch was just released on Friday,

[52:47 - 52:49]  which I'm just so excited for it.

[52:49 - 52:52]  Like it's literally been like hundreds of hours

[52:52 - 52:56]  prepping this like up until this point like so much work has gone into this

[52:56 - 53:00]  all the things that I'm showing here in this stream building this agent like I go

[53:00 - 53:04]  into a lot more detail things around the PIV loop how we can build reliable

[53:04 - 53:09]  and repeatable systems so that we can create our own process to build our own

[53:09 - 53:15]  software optimally because in the end most developers have what I like to call the

[53:15 - 53:21]  system gap where they're using AI coding assistance more willy-nilly, if you will, right?

[53:21 - 53:24]  And like, that's what I'm trying to teach you how to not do.

[53:24 - 53:27]  Because people who don't get good results with coding assistance,

[53:27 - 53:30]  and like, that'll happen.

[53:30 - 53:31]  Like, if you don't have a good system in place,

[53:31 - 53:33]  it's not gonna work that well.

[53:33 - 53:34]  Your code's just gonna break down,

[53:34 - 53:36]  especially when you go into production.

[53:36 - 53:39]  And so you need to have a system in place.

[53:39 - 53:40]  Reusable, prompt and commands,

[53:40 - 53:42]  defining your rules and workflows,

[53:42 - 53:45]  how you integrate different tools with your coding assistant,

[53:45 - 54:43]  how you optimize your code base to work with AI, like all these things that are not trivial, but very important so that you can actually get good results realistically. It takes a lot of work up front. And that's what I show you how to do. And so, yeah, right now that I have the link for Dynamis highlighted and also the discount code that's only going to be available for this live stream. Like I've got to make sure you know that so that you don't expect to be able to use it after. 20% off monthly and 40% off the yearly membership right now. For this course and then also everything that we have in Dynamis, the community, the weekly workshops, the AI agent mastery course. It is really the whole shebang that you're getting within Dynamis. And so I'm just continuing to build more and more into the community. So it's just more valuable over time. And this course is like the big thing that I'm doing right now for that. So yeah. All right. I'll go ahead and tear that down

[54:43 - 54:51]  here. And let's go back over to our coding assistant and see where we're at. Cool. So it is

[54:51 - 54:57]  failing to read some files, which it's fine because it looks like it's retrying. I'm not really sure

[54:57 - 55:02]  what it's trying to do. There's probably like something that I called out on accident for a piaproject.tomel,

[55:02 - 55:07]  but that's all fine. So okay, we have our code-based analyst sub-agent

[55:07 - 55:08]  that I have running right now

[55:08 - 55:11]  to analyze what we have set up so far,

[55:11 - 55:14]  which is basically just gonna be analyzing

[55:14 - 55:16]  the examples that we have at this point.

[55:16 - 55:18]  And so it's going through the examples

[55:18 - 55:20]  to understand how to build the RAG pipeline.

[55:20 - 55:23]  I mean, this is the main file that I need it to reference right now.

[55:23 - 55:25]  So as long as it does that, I think we're good.

[55:25 - 55:29]  And then after that, it's going to create our structure plan.

[55:29 - 55:58]  And so maybe while it's continuing to go here, I'll just answer some questions that we've got in the chat. So let me take a sip break and I'll open up the chat as well. All right. Can I switch from monthly to yearly? I just joined for a month to see if it's worth it. Yes, that is an option. So yeah, I appreciate you asking if you go and message me in the community,

[55:58 - 56:00]  I can help you out with that.

[56:04 - 56:06]  Let's see, can Claude code give us a warning

[56:06 - 56:08]  when we get close to our token limit?

[56:08 - 56:10]  That's a good question.

[56:10 - 56:13]  I believe you can with Claude hooks.

[56:13 - 56:16]  I've never done that before, but also,

[56:16 - 56:17]  like when you're working in Claude

[56:17 - 56:19]  and you get close to your context limit,

[56:19 - 56:21]  you'll see an error, or not an error.

[56:21 - 56:25]  You'll see like a little warning right here kind of in like the bottom

[56:25 - 56:29]  right of your terminal that'll say that you have like 5% or 8% left of your context window

[56:31 - 56:36]  and so yeah I mean that's kind of like the warning that you'll get in the UI if you wanted some

[56:36 - 56:39]  kind of alert you could probably do something with Claude hooks I would say

[56:41 - 56:46]  what do you think about Claude Skills yeah actually I just did a workshop in Dynamis on Claude

[56:46 - 57:43]  skills which yeah I'll go show that really quick. So Claude skills, for those of you who don't know, it's a kind of something that might honestly replace MCP servers because it's a way to load instructions into a coding assistant for how to use different tools only when it actually needs to use those tools. So like, for example, with Archon as an MCP server, the context for ArCON is always loaded in to the coding assistant. And so it takes a lot of the context window. But what if you had a little description of like, here's what ARCON does. Now only use ARCON as a skill and like load in the context when you want to do task management or search the knowledge base, for example. So it'll load in the instruction set for ARCON and then like all these scripts to basically like use ARCON with code. That's what skills give us. And I have been very impressed with skills like it solves a big problem that we have right

[57:43 - 57:49]  now with um just like a lot of tools like in mcp servers right now where they just take so much

[57:49 - 57:55]  context and with our a i coding assistants especially we hit those context limits so fast and so we need

[57:55 - 58:02]  a way to like basically only dynamically reference different capabilities when we actually need them

[58:02 - 58:06]  that's kind of the core of what claude Skills gives us.

[58:06 - 58:08]  So yeah, I'm very bullish on skills.

[58:08 - 58:11]  I think that they could entirely replace MCP servers.

[58:12 - 58:17]  Not to get too technical, the one thing I feel like MCP servers do better is environment variables.

[58:17 - 58:23]  There's not really a way to like configure environment variables for skills like you can do with MCP,

[58:23 - 58:25]  like when you connect a MCP client to a server.

[58:26 - 58:36]  So, yeah, but otherwise I think they're fantastic. So it's like a branch expansion context updater.

[58:37 - 58:38]  I mean, you could think of it like that, yeah,

[58:39 - 58:42]  because you kind of have different layers of context that you load when you need it.

[58:42 - 58:46]  Like I can load a skill and that has like the core instructions.

[58:46 - 58:51]  And then the core instructions can also reference other documentation to bring in

[58:51 - 58:53]  if I need that part of the skill specifically.

[58:54 - 58:57]  And so that way you can have like a really massive instruction set,

[58:57 - 59:00]  but you're not like loading it all into the lm at the same time only when it

[59:00 - 59:05]  actually needs it which by the way is similar to how i set up my global rules um so the global

[59:05 - 59:11]  rules for this project just as the coding assistant continues to go here the global rules for this

[59:11 - 59:18]  project i i say like when you are building tools then look at my tool guide right so like i have a

[59:18 - 59:51]  part of my rules for like how to build effective tools so this is like part of my global rules, but I'm only telling it to look at it if it is actually actively building tools. Otherwise, it doesn't make sense to dilute my context with this information. Because like right now, as I'm working on the RAG pipeline, I'm not doing anything with tools. Like why should I have that in my context window? But then when I'm building the agent and I'm building the RAG tools for the agent, then I definitely want this, right? So I hope that makes sense.

[59:51 - 59:54]  Toby said the coding course is great.

[59:54 - 59:56]  Just finished the two layer planning video today.

[59:56 - 59:59]  Awesome. Appreciate that Toby. Cool. Thanks for going through it.

[59:59 - 60:01]  Can I watch this stream later on?

[01:00:01 - 01:00:05]  Yeah, 100%. So this live stream is going to be available on my channel

[01:00:05 - 01:00:09]  like pretty much just a couple of hours after it's done.

[01:00:09 - 01:00:11]  It just takes time for YouTube to process it, I believe.

[01:00:11 - 01:00:18]  But if you go to my channel and, oh, that's cool. I've never seen my, I've never looked at my own channel from a different account before.

[01:00:19 - 01:00:21]  But yeah, well, while it's live, I mean.

[01:00:21 - 01:00:28]  But yeah, so if you go to the Live tab, then this will be like a full recording afterwards.

[01:00:28 - 01:00:32]  Like all my past live streams, you can view those just like a YouTube video if you just go to the Live tab.

[01:00:35 - 01:00:40]  Is the Rag Agent Tables SQL file something you configured before for this specific agent?

[01:00:41 - 01:00:45]  Or is it from an old agent to show the architecture on how to do the tables?

[01:00:45 - 01:00:51]  Good question, Toby. Yeah, so the file that he's calling out explicitly is this one right here.

[01:00:51 - 01:00:59]  This is from a previous agent. So I just wanted to reference this SQL file so that it understands

[01:00:59 - 01:01:05]  my preferences around building scripts to like set up tables for my agent. And then also I wanted to

[01:01:05 - 01:01:11]  reuse some of these tables like the requests and conversations and messages because those are the

[01:01:11 - 01:01:17]  tables that I needed to set up exactly like that for it to be compatible with the front end application

[01:01:17 - 01:01:21]  that I have right here. So I hope that makes sense. So yeah, it's just an example from a previous

[01:01:21 - 01:01:27]  agent. Everything I have in the examples folder is from previous implementation, including the SQL.

[01:01:29 - 01:01:34]  So, okay. All right, we have our YouTube Rang pipelineeline Request.

[01:01:34 - 01:01:37]  So I'm gonna go into my request folder.

[01:01:37 - 01:01:39]  I typically like to store all of my requests

[01:01:39 - 01:01:42]  in a special folder in my code base.

[01:01:42 - 01:01:46]  So I could, if I want to, even like check this into source control

[01:01:46 - 01:01:48]  so that I have a record of my plans

[01:01:48 - 01:01:51]  that I've used to build everything in my different Pibloops.

[01:01:52 - 01:01:54]  And so I'll go ahead and open this up.

[01:01:54 - 01:01:57]  And so this follows exactly the structure

[01:01:57 - 01:02:01]  that I have defined in my create plan command.

[01:02:01 - 01:02:03]  And so we've got the overview.

[01:02:03 - 01:02:05]  We have the requirements summary,

[01:02:05 - 01:02:09]  the architecture requirements, our research findings.

[01:02:09 - 01:02:12]  So it did a ton of research as a part of that planning

[01:02:12 - 01:02:15]  to create this structure plan.

[01:02:15 - 01:02:16]  We've got the Dockling hybrid chunking,

[01:02:16 - 01:02:19]  which it keeps spelling it wrong, but I'm just gonna leave it.

[01:02:19 - 01:02:21]  I think that's fine.

[01:02:21 - 01:02:23]  If I was really nitpicky right now and I wanted to spend some time

[01:02:23 - 01:02:25]  with it, I would correct little things like that.

[01:02:25 - 01:02:28]  But right now I'm just going to call that good.

[01:02:29 - 01:02:34]  We're using SuperBase with PGVector, and it's referencing things based on

[01:02:36 - 01:02:39]  what it saw in the examples, which is looking really good.

[01:02:40 - 01:02:46]  Code-based integration points. So it's calling out existing patterns to follow.

[01:02:46 - 01:02:51]  So I want to make sure, as long as it's not going to try to build things into the examples folder,

[01:02:51 - 01:02:52]  I hope that it doesn't do that.

[01:02:53 - 01:02:56]  So maybe I'll call it out explicitly, but otherwise this is looking really good.

[01:02:59 - 01:03:01]  Yeah, okay, no, this is actually perfect.

[01:03:01 - 01:03:06]  So one of the things that I have it give me is the desired code-based structure.

[01:03:06 - 01:03:09]  So it actually outlines the RAG pipeline

[01:03:11 - 01:03:14]  and it's got my chunking service, my Benning Service. This looks really, really good.

[01:03:14 - 01:03:17]  And it's got the tests for the RAG pipeline as well.

[01:03:17 - 01:03:45]  One thing that I feel like it doesn't need to do right now is create the RAG tools. And so I'm just going to tell it here, like, don't create the RAG tools right now. We're just focusing on creating the RAG pipeline. So update the plan for that. And then also make sure you're very explicit here that we're not to actually create any code in the examples folder. All right, there we go. So just a little bit of iteration. And I would spend a lot more time iterating on this generally. But overall, this looks pretty good. So I'm going to jump into an implementation

[01:03:45 - 01:03:47]  with this in just a second here.

[01:03:47 - 01:03:50]  Because I want to get the RAG pipeline knocked out

[01:03:50 - 01:03:53]  so that we can test this with YouTube content

[01:03:53 - 01:03:57]  and then also go on to making the agent.

[01:03:57 - 01:03:58]  And I want to be able to see it in action

[01:03:58 - 01:03:59]  by the end of the stream here.

[01:04:00 - 01:04:03]  So OK, let me scroll back down.

[01:04:03 - 01:04:04]  Implementation tasks.

[01:04:04 - 01:04:06]  So this is really good too.

[01:04:06 - 01:04:07]  Like we have our task that's like starting

[01:04:07 - 01:04:36]  with environment configuration, going into defining our schemas what else we got here database migration let's see creating a our first database schema script very nice um well here i actually don't like that i'm going to say one more thing uh don't call it a database migration just do the initial setup sequel uh because i'm starting from a fresh database here okay there we go.

[01:04:36 - 01:04:39]  I'm just kind of correcting a couple of assumptions that it has overall.

[01:04:40 - 01:04:42]  But yeah, like this is looking really, really good.

[01:04:43 - 01:04:46]  The way that it's doing the chunking, the embedding service.

[01:04:46 - 01:04:49]  I'm just glancing over this like really, really quickly.

[01:04:50 - 01:04:52]  This is kind of a long plan overall.

[01:04:53 - 01:04:56]  It's 2,000 characters, which is that is way too long.

[01:04:57 - 01:04:58]  So I don't like that.

[01:04:59 - 01:05:31]  Because the problem is it like basically wrote all of the code already. So in an ideal plan, and like sometimes Claude just decides to do this, where it'll include like all the code, even when I'm just only in the planning phase right now. When it does this, like a lot of times, I'll just ask it to make it way more concise. I don't need all the code right away, right? And so for the sake of brevity, I'm not going to ask it to do that right now typically though i like my plans to be more like 500 to a

[01:05:31 - 01:05:41]  thousand lines not 2 000 like it definitely went too far here but i think this will still work pretty

[01:05:41 - 01:05:46]  well because the only reason it's long is because it kind of did a lot of the coding already

[01:05:46 - 01:05:52]  which it already did research on super data and dockling and things like that so like it knows

[01:05:52 - 01:05:56]  how to use those libraries right so i think that the code that it's in the planning here is probably

[01:05:56 - 01:06:01]  more than even just pseudo code like i think this is like good code that it can build right into

[01:06:01 - 01:06:07]  the file structure as it creates it here so i'm just going to let it rip and uh once this is done here

[01:06:07 - 01:06:15]  and we'll see how it goes clod 4.5 loves to just charge ahead with things yep indeed that is

[01:06:15 - 01:06:50]  what it is doing here um yeah um yeah um In Dynamis, there already exists an internal agent as we build on this master class. So I'm not sure exactly what you're referring to, but in the AI agent mastery course that we've gone in Dynamis, there is a complete AI agent that I build as a part of that. That's a template for you. It's got a full RAG pipeline that works with local files or Google Drive. It's got an AI agent with web search and image analysis and RAG tools and agenticic rag and i have it both within n8n and in python and then i

[01:06:50 - 01:06:54]  have the full front end set up um as well so like this what what you're looking at right here

[01:06:54 - 01:07:00]  like this is actually the dynamist agent that i was chatting with as that brief example so yeah

[01:07:00 - 01:07:04]  uh there is like and there's a lot of other like complete agents built out from like workshops and

[01:07:04 - 01:07:11]  stuff i've done in the community as well so there's a ton of value there 100%. so yeah all right um

[01:08:05 - 01:08:05]  what are we doing here? Okay, so now it's just updating the database stuff for me. So good. Okay, we're almost ready for the implementation phase here. Do you ever find that it hallucinates when you add too much context or content? Yeah, so 100%. That's why I'm a little uncomfortable with how long the plan is right now. But because the plan is mostly just long because of code, I think I'll be okay okay but yeah if you were to if this plan was 2,000 lines because it was like it literally had to be to like outline all of the features I was trying to build at once then 100% it will hallucinate right like as long as you're not asking it to code too much at once like I think this is a pretty reasonable request overall just based on my experience with coding assistance then you're fine but if I was trying to ask it to like build the YouTube rag pipeline, and build the agent,

[01:08:07 - 01:08:10]  and build in observability with length, like all these things and, like, support other sources,

[01:08:10 - 01:08:11]  like, geta repos.

[01:08:11 - 01:08:12]  If I was trying to do that all at once,

[01:08:12 - 01:08:13]  then it would hallucinate,

[01:08:13 - 01:08:16]  because this document would be 3,000 lines long

[01:08:16 - 01:08:19]  because I'm just asking for too much at the same time.

[01:08:20 - 01:08:21]  So, yeah.

[01:08:22 - 01:08:24]  All right, how close are we?

[01:08:24 - 01:08:25]  All right, we are good here.

[01:08:25 - 01:08:28]  So we have our plan.

[01:08:28 - 01:08:29]  I'm gonna call this good.

[01:08:29 - 01:08:31]  I'm just gonna go and let it rip now.

[01:08:31 - 01:08:35]  And so generally I do quite a bit more validation here and shrink it.

[01:08:35 - 01:08:37]  But I'm going to get into the implementation now.

[01:08:37 - 01:08:39]  So I'm going to clear my conversation.

[01:08:40 - 01:08:44]  I'm going to say Claude is doing fine because I wasn't super impressed with the plan.

[01:08:44 - 01:08:45]  But that's okay.

[01:08:45 - 01:08:47]  So now I'll go into execute plan.

[01:08:48 - 01:08:52]  And so this command is similar to the create plan, right?

[01:08:52 - 01:08:54]  It's just it's a standard operating procedure.

[01:08:54 - 01:08:55]  It's a step by step.

[01:08:59 - 01:09:00]  I want you to read my plan that I have here,

[01:09:04 - 01:09:13]  and then I want you to execute it task by task. And another thing that I have as a part of this plan here is I instruct it on how to create the tasks in ARCON. So all of the tasks that we

[01:09:13 - 01:09:19]  have in that implementation plan part of my structured plan, it's going to create these tasks in

[01:09:19 - 01:09:48]  Arcon, and then it's going to go through this implementation cycle for each of them. And so going back to our diagram here, we just finished our structure plan. Now we move on to implementation, where we are delegating all of the code to the coding assistant. And so we're gonna let it go for quite a while here, and then we'll validate everything at the end, right? So I'm delegating it. The first step of planning and the last step of validating, that's where I wanna be very involved. But when it comes to the actual implementation,

[01:09:48 - 01:09:51]  I am trusting but verifying, giving it the plan,

[01:09:51 - 01:09:54]  trusting it to do a good job, and then I just do the validation

[01:09:54 - 01:09:55]  at the end.

[01:09:55 - 01:09:56]  So let's go ahead and kick that off here.

[01:09:58 - 01:09:59]  So I'm gonna go in, execute plan,

[01:09:59 - 01:10:02]  and then the path is PRP slash request,

[01:10:02 - 01:10:06]  YouTube ragpipeline.md, just calling out the path

[01:10:06 - 01:10:07]  to this file right here.

[01:10:07 - 01:10:09]  And we're doing this in a brand new conversation

[01:10:09 - 01:10:13]  because our plan is literally all of the context it needs.

[01:10:13 - 01:11:06]  There's nothing else it needs from my previous conversation. It doesn't need to do any more research right now. Like, it just needs to look here because we also call out the different files and examples to look at for the implementation as well. So I'm gonna go ahead and let it rip here. So yeah, while we do that, I'll just go ahead and answer some more questions in the chat here. Like I said, casual live stream. We just get to watch Claude, go, and Cod code go and chat about whatever you guys want to. So let me go back to the chat. Oh, I appreciate that. Well done on a great stream. Thank you very much, yeah. And I've never built an agent live before, so I've never done something like this. It's a little bit slower than I wanted, but I also think it's important to, like, explain things as I'm going through it. Instead of just blazing through stuff, like executing the plan or creating the plan.

[01:11:06 - 01:11:09]  I'm going as fast as I can, reasonably, I think.

[01:11:09 - 01:11:12]  Also, I'm getting the, so Claude code loves to, like,

[01:11:12 - 01:11:14]  stutter a bunch when it's doing things in parallel.

[01:11:14 - 01:11:16]  So I'm gonna, like, hide that for a second,

[01:11:16 - 01:11:18]  because that is really ugly.

[01:11:18 - 01:11:20]  Okay.

[01:11:20 - 01:11:22]  Let's see.

[01:11:22 - 01:11:24]  Do you try to run as much of this locally?

[01:11:24 - 01:11:27]  If so, what hardware do you have in terms of CPU and GPU?

[01:11:27 - 01:11:29]  Thank you.

[01:11:29 - 01:11:30]  Yeah, good question.

[01:11:30 - 01:12:37]  So, I do want to build this agent in a way where I can run things locally. So in the examples here, this AI agent that I have as my previous project, that is an example, I do actually have it set up so that you can change the LLM and embedding model to be Olamma if you want to run everything locally. Now I don't try to run as many agents locally as I possibly can because local large language models are always going to be not as powerful as the cloud the big cloud ones right now at least right now so like um so clots on at 4.5 gpt 5 like those models are better than anything you can run locally but if your application has sensitive information or you just need it to be private for whatever reason then you have to use local AI like it is a super important concept and so i do create a lot of agents that are local because I'm working with things like, you know, like my internal knowledge base that I have as I'm planning YouTube videos, for example, and I want an agent to help me with that ideation, but I don't want it to be something that's just like sending all of my content ideas to open AI just as an example.

[01:12:37 - 01:12:46]  Or like I've worked with companies before where they do actually have like local LLMs running on their code base because it's very proprietary technology that they're working on.

[01:12:46 - 01:13:50]  And so, yeah, it is important to understand how to use local AI. I mean, like setting it up in an agent like this, it's pretty simple overall, and then also like when you should use local AI, because it's not always a solution. And generally for any kind of like internal application, it's a good consideration. For anything that's like an external facing agent, like a voice agent that handles inbound calls, or if you are building like a lead, a handling agent, like that kind of thing should probably not be using local AI because it's frontward facing, it's not sensitive data anyway and then you want it to be a faster and more powerful as far as hardware let me pull up something really quickly because I have my exact build saved in PC part picker.com so I can I can load that up I'll take the time to do this because I feel like you guys would actually appreciate this but I have a saved build that has my part list. Save part list. Boom, boom. Let me make sure this works.

[01:13:50 - 01:13:55]  I'm going to make sure this link is not a... Okay, yeah, okay. Cool. Let me go paste this here.

[01:13:55 - 01:14:01]  So this is a link to my exact PC build. If you're curious, I have two 30-90 graphics cards.

[01:14:03 - 01:14:36]  I got them used off of eBay. So my computer's not actually as expensive as it says here. Not nearly as expensive. But yeah, that's my build. So I hope that helps. And it does do really well for running local LMs. Sounds like the Create Plan command needs some more guardrails. Honestly, it usually does a lot more better than this. Wow, that was terrible English. Usually it does a lot better than what it did now in terms of making the plan more concise

[01:14:36 - 01:14:40]  But yes Tony I should probably improve my create plan

[01:14:40 - 01:14:48]  This this isn't like the plan the create plan I typically use. I just kind of put something together to make it a bit more concise for this stream

[01:14:49 - 01:14:54]  But yeah usually I would have something that's more explicit about like being more simplistic and just outlining the

[01:14:54 - 01:14:56]  The plan versus the code

[01:14:56 - 01:15:00]  That's the main guardrail that I should have incorporated better into here.

[01:15:02 - 01:15:04]  So yeah, definitely should be improving that.

[01:15:05 - 01:15:05]  I appreciate this, Beau.

[01:15:06 - 01:15:07]  The community is well worth the money if you're on the fence.

[01:15:07 - 01:15:08]  It may seem expensive,

[01:15:09 - 01:15:10]  but you get a ton of resources

[01:15:10 - 01:15:12]  and access to coal and other very responsive members.

[01:15:12 - 01:15:13]  That means a lot, yeah.

[01:15:13 - 01:15:15]  And I'm active in the Dynamics community

[01:15:15 - 01:15:17]  literally every single day.

[01:15:17 - 01:15:19]  And there is an event going on in Dynamis

[01:15:19 - 01:15:20]  every single day.

[01:15:20 - 01:15:22]  We've got workshops, office hours.

[01:15:22 - 01:15:24]  I started this thing recently called

[01:15:24 - 01:15:25]  the AI Exploration Hour,

[01:16:26 - 01:16:32]  where it's just like a more casual event for us to chat about the latest AI tech and then just dive into it together. And so if you're ever curious, like, what are the things that I should pay attention to right now? Like, is Claude Skills actually worth it? Like, come to the hour and we'll talk about the things that are big right now and explore and see if it's actually worth our time, right? That's a big thing, like just trying to fight through the fluff. Like, that's one of the goals that I have for you in Dynamis is to just help you fight through the fluff like learn the skills that are important to learn Avoid the the shiny objects that aren't worth your time I think that's that's just like a big problem that we have in the AI space right now is there's just so much That says coming out every single weekend like half of it or more just like doesn't even matter, but it's hard to tell what doesn't matter Versus like what should we try to incorporate into our coding workflows or build into our agents or you know use as a tool to replace xyz it's hard to figure that out um cold has a 60 to 90 minute working session nearly every friday at lunchtime eastern recorded as office hours hang out okay

[01:16:32 - 01:16:37]  founding member love it cool yeah i appreciate that yeah there's like just what i said basically

[01:16:37 - 01:16:41]  but yeah i appreciate you calling that out sorry i didn't see your other message before i

[01:16:41 - 01:18:02]  basically said that myself um Which plan are you using right now in Claude? What about rate limits? Yeah, so I'm using the $200 month max plan right now, and I like never hit rate limits with Sonnet 4.5. I know people that are using the $100 month plan, and they generally don't hit rate limits either unless they're using Opus 4.1. There's been a lot of complaints about rate limits in general with Claude code recently. and so I know that it is considered like a pricier tool overall because you have to have the higher tiers to not hit rate limits. It's well worth it to me though because it is the best, in my opinion. I think that Codex is the second best coding assistant and I even did a video recently on my channel showcasing using Codex actually like programmatically through the Codex SDK. That was pretty cool. So I'm impressed with Codex as well. I think that there are a lot of very, very viable alternatives to ClaudeCode. Codex and the Gemini CLI being the main two that I would prefer if I couldn't use cloud code. So, yeah, you're definitely not tied to it. And like everything that I cover and that I'm covering here, everything I cover in the Agentic Coding course, it is AI coding assistant agnostic, right? Like the principles that I teach and like what we're doing right here with the PIV loop, that works no matter the coding assistant that you're using.

[01:18:04 - 01:18:05]  Because I think it's really important to not get tied to one tool.

[01:18:06 - 01:18:07]  The mantra that I always say,

[01:18:08 - 01:18:10]  and like this is another gold nugget for you guys,

[01:18:10 - 01:18:12]  is capabilities over tools, right?

[01:18:12 - 01:18:14]  Like focus on the high leverage skills

[01:18:14 - 01:18:15]  that are going to apply

[01:18:15 - 01:18:17]  no matter the problem you're solving

[01:18:17 - 01:18:19]  instead of getting really in the weeds

[01:18:19 - 01:18:21]  about trying to master specific tools.

[01:18:22 - 01:18:23]  Like I honestly don't care

[01:18:23 - 01:18:26]  how comfortable I am with Claude code.

[01:18:26 - 01:18:54]  Like it matters to an extent. But the thing that really matters is, like, my skills around how I apply AI coding assistance and, like, how I build my system in a way that works no matter the coding assistant. Like, that's the real high-leverage skill there and what I teach. So I hope that makes sense. It's always a good idea to break down large tasks and create individual arc-on tasks for each step. 100%.

[01:18:54 - 01:18:55]  Yeah, and actually let me show my Arcon,

[01:18:55 - 01:18:57]  because I don't know if you guys were watching the logs

[01:18:57 - 01:19:02]  here as I was talking, but we're using the Arcon MCP server

[01:19:02 - 01:19:05]  to create a project and tasks for our pipeline here.

[01:19:05 - 01:19:07]  So let me go into projects.

[01:19:08 - 01:19:11]  We have our YouTube Rag pipeline and take a look at that.

[01:19:11 - 01:19:16]  It created how many, yeah, okay, 12 tasks in total,

[01:19:16 - 01:19:17]  and it's actually already almost done.

[01:19:17 - 01:19:19]  So we're just to the point right now

[01:19:19 - 01:19:22]  we're doing validation. And so one of the things that I have built

[01:19:22 - 01:19:28]  into my structure plan is I give the AI coding assistant instructions on how to validate its own

[01:19:28 - 01:19:36]  work. Right. So we have a structure plan. We're in the middle of implementing. And in a second here,

[01:19:36 - 01:19:43]  it's almost done. We're going to do validation. But also, validation is more than just a human effort.

[01:19:43 - 01:20:15]  It is also an AI coding assistant effort. We want to be very explicit to the coding assistant on how it can check its own work. And that's one of the things that I have defined in my structured plan. So I tell it how it writes unit tests, how it writes integration tests, and then it'll run those and iterate on them until everything is passing. And then at that point, it gives control back over to us to do our validations like code review, which I'm not going to do much of actual code review in this live because I think that's more boring and I need to be pretty brief here but like this is super

[01:20:15 - 01:20:19]  important so like don't skip that and then even if you're not very comfortable with

[01:20:19 - 01:20:23]  using or like if you're newer to coding and like you don't really know exactly how

[01:20:23 - 01:20:27]  to do a code review that's okay because you can just instead of like looking at

[01:20:27 - 01:20:31]  the code yourself you can just ask the coding assistant questions like did you

[01:20:31 - 01:20:36]  address this did you address that how does this API work how is our database being

[01:20:36 - 01:20:40]  set up right and like you can kind of review just by asking it questions like a, you know,

[01:20:40 - 01:20:46]  typical non-technical project manager might. And then obviously the fun part doing the manual

[01:20:46 - 01:20:51]  tests, like we will run the rag pipeline, watch it pull my videos and put those into a knowledge

[01:20:51 - 01:20:56]  base. That is what we're going to get to in just a little bit here as the final layer of validation.

[01:20:56 - 01:21:00]  So validation strategy is one of the things that I have in the structure plan. And I can

[01:21:00 - 01:21:32]  show that really quick as we're wrapping up the implementation here. Like if I go to my Create Plan command and I scroll all the way down, one of the things that we have is the validation, right? So like before finalizing the plan, or no, this isn't the right place. Sorry, that's validation for the plan itself. What I meant to refer to is this right here, the testing strategy, right? Like create the unit tests, create the integration tests. Here are the edge cases that we need to cover and so that when within our plan

[01:21:32 - 01:21:42]  explicitly if i go down to validation well i guess i can't search a preview

[01:21:42 - 01:21:47]  let me scroll down uh here we go so phase four testing like unit tests here are the tests that it

[01:21:47 - 01:21:53]  should be creating right and then like here are our integration tests and then here's our

[01:21:53 - 01:21:57]  validation around linting right like instructing on how to do those things,

[01:21:57 - 01:21:59]  task by task, and it created that all

[01:21:59 - 01:22:01]  is a separate task in Arcon as well.

[01:22:01 - 01:22:02]  So that's what it's doing right now.

[01:22:02 - 01:22:04]  So it actually is to the end of the testing

[01:22:04 - 01:22:06]  where it's creating the,

[01:22:06 - 01:22:08]  or it's doing the linting test with MyPy.

[01:22:13 - 01:22:15]  Or I guess MyPy is for type checking.

[01:22:15 - 01:22:17]  Yeah, so rough is for linting.

[01:22:18 - 01:22:20]  Anyway, that's too technical.

[01:22:29 - 01:22:35]  All right. You should try native cursor again. Ross Mick did a video and said it's ripping right now. I did actually see his video. Oh, I didn't watch his video, but I saw it was like

[01:22:35 - 01:22:40]  recommended to me. So yeah, I do want to check it out. Because yeah, I mean like part of my,

[01:22:40 - 01:22:46]  my job for all of you guys is to constantly be on top of like I said, cutting through the fluff.

[01:22:46 - 01:22:48]  Like what are the tools that are actually worth paying attention to?

[01:22:49 - 01:22:53]  And like, that's what Raz Mix is doing as well. Like he's trying out cursor again. He's figuring out like,

[01:22:53 - 01:23:01]  oh, shoot, like, this is good. And, and yeah, I think I'm allowed to say this. I got like a little bit

[01:23:01 - 01:23:07]  of pre-release information that cursor 2.0 is coming out rather soon here. And I am going to be getting

[01:23:07 - 01:23:12]  like a preview access to it. So I might be sharing that with you all in a video. Like we'll see.

[01:23:12 - 01:23:19]  It just depends on how impressed I am with it because I'm not going to show you guys something unless I really think it is worth paying attention to.

[01:23:20 - 01:23:24]  And like even for sponsors, I'll do that. Like I turn down sponsors all the time that I think are just stupid.

[01:23:25 - 01:23:29]  Or not, well, that's mean. And not worth your time. Like it's part of the fluff.

[01:23:30 - 01:23:37]  Just being blunt. And so like, yeah, I'll cover Cursor 2.0 if I really am impressed with it. But like, I will try it out 100% Chris.

[01:23:37 - 01:23:40]  And I think there is a good chance that it will impress me.

[01:23:40 - 01:23:43]  Because I do know, I've heard recently that it's pretty good.

[01:23:48 - 01:23:49]  Archon works like a charm.

[01:23:49 - 01:23:52]  First time using it in such a Greenfield project.

[01:23:52 - 01:23:52]  Cool.

[01:23:52 - 01:23:53]  Glad to hear it.

[01:23:53 - 01:23:54]  Nice.

[01:23:54 - 01:23:54]  Yeah, yeah.

[01:23:54 - 01:23:59]  If you guys want to try out Arcon, it is a completely free and open source tool that I've just

[01:23:59 - 01:24:03]  been building on my channel recently, or kind of like for my channel recently.

[01:24:03 - 01:24:05]  Got a team behind it as well.

[01:24:06 - 01:24:12]  And yeah, it is all about giving you yourself a command center for working with AI coding assistance.

[01:24:12 - 01:24:19]  And so kind of like what we are using it for right now, we have our knowledge base where we're pulling knowledge like super data, for example.

[01:24:19 - 01:24:25]  So it can like look at how to leverage super data in Python code or using Pidentic AI to build our agent.

[01:24:25 - 01:24:27]  And then we have the projects as well.

[01:24:27 - 01:24:31]  So it gives a Canband board for us to manage projects.

[01:24:31 - 01:24:58]  And the coding assistant gets to through the mcp server as well so it's an interface for human and AI collaboration right that's the beautiful thing that we're we're trying to do with arc on is like building this single application that has all of the human AI collaboration points that you need for coding and even extending beyond coding for just like general agents at some point as well not to spoil too much of what we have in store for arc on but definitely you got big things coming for it.

[01:25:04 - 01:25:05]  And it's a blast to like use this as a part of any development workflow like I'm doing right now.

[01:25:06 - 01:25:07]  So, yeah.

[01:25:09 - 01:25:09]  I appreciate that a lot, Yandi.

[01:25:10 - 01:25:11]  Thank you.

[01:25:13 - 01:25:14]  Hoping for an obsidian setup walkthrough.

[01:25:14 - 01:25:15]  Ah, yeah.

[01:25:16 - 01:25:16]  I could do that.

[01:25:23 - 01:25:23]  You know, it's kind of interesting because if I cover like my obsidian setup, I mean, sure, I have some AI things in it.

[01:25:50 - 01:25:53]  But it'd kind of be like my first video ever where it's like the main topic isn't actually AI so I don't know we'll see I might do that though I think it would be a useful video to just like show how I use obsidian and like the Zettelcasting technique in general love Arcon currently grinding through a project for me cool Barry love it yeah that's always the most satisfying thing when you can just have a coding assistant rip through something while you're doing something else, multitasking, watching a stream, taking your dog out for a walk,

[01:25:53 - 01:25:56]  playing video games, working with another coding assistant,

[01:25:56 - 01:25:59]  like whatever it is, that's always the best.

[01:26:01 - 01:26:05]  I need a Twitter bot, my dog.

[01:26:05 - 01:26:06]  A Twitter bot?

[01:26:06 - 01:26:08]  What do I need a Twitter bot for?

[01:26:10 - 01:26:10]  Maybe.

[01:26:12 - 01:26:13]  Crew AI?

[01:26:13 - 01:26:14]  Crew AI.

[01:26:14 - 01:26:18]  So I'm using Pont AntANTIAI for our build here,

[01:26:18 - 01:26:19]  because I prefer it overall.

[01:26:19 - 01:26:22]  I think crew AI is a pretty great Python library

[01:26:22 - 01:26:23]  for building agents.

[01:26:23 - 01:26:26]  It's a good agent framework, especially for multi-agents

[01:26:26 - 01:26:27]  and making that really simple.

[01:26:27 - 01:26:29]  But I definitely feel like I have a lot more control

[01:26:29 - 01:26:32]  and customizable when I'm building with Piedanthi

[01:26:32 - 01:26:33]  AI specifically.

[01:26:33 - 01:26:35]  It's less of an abstraction.

[01:26:35 - 01:26:38]  And so it's less of a black box, right?

[01:26:38 - 01:26:41]  Like when you're using crew AI, they make a lot of,

[01:26:41 - 01:26:45]  I guess I'd say it's more opinionated of a framework like you get to

[01:26:45 - 01:26:53]  customize things less I think that's kind of how I'll leave it um good question

[01:26:53 - 01:26:56]  do you have a meta prompt generator for creating the best possible prompt

[01:26:56 - 01:27:03]  example a prompt for plan creation or it's just fluff yeah so the the

[01:27:03 - 01:27:14]  meta prompt generator that I use for AI coding it really is the structured plan that I outline in the plan, right? Like this,

[01:27:14 - 01:27:24]  let me go to the top here. So this part right here, like this entire, or wait, sorry, no, I need

[01:27:24 - 01:27:30]  to go down here. Okay, there we go. This right here. All of this is outlining the core

[01:27:30 - 01:27:36]  components that I want of my structure plan. This kind of is my metaprompt. And so like I inject this as a part of some planning

[01:27:36 - 01:27:42]  command and I say like use this as your template to create the structure plan. So it kind of is my

[01:27:42 - 01:27:48]  metaprompt generator, if you will. Now for like an AI agent system prompt, for example,

[01:27:48 - 01:27:52]  I don't have something like that because I think that would be pretty rigid. But generally I

[01:27:52 - 01:27:58]  have like my core components to a system prompt that I'll follow. And I'll use an AI

[01:27:58 - 01:28:01]  coding assistant to help me outline that.

[01:28:01 - 01:28:03]  But I wouldn't say I have like a meta-prompt generator

[01:28:03 - 01:28:04]  for something like a system prompt.

[01:28:04 - 01:28:05]  If that makes sense.

[01:28:06 - 01:28:08]  But good question though.

[01:28:10 - 01:28:12]  Yeah, learn the technology versus the tools.

[01:28:12 - 01:28:14]  Right, yeah, like when I said capabilities not tools,

[01:28:14 - 01:28:15]  that's exactly what I meant.

[01:28:15 - 01:28:17]  Yeah, so well said, yeah.

[01:28:21 - 01:28:23]  This Pidentic AI have multi-agent system.

[01:28:23 - 01:28:25]  We're using Lange graph.

[01:28:25 - 01:28:55]  Yeah, so Pident a i does support building pyndantic ai multi-agent systems like as graphs they do support that i still think that lang graph is a lot more robust though they also had their 1.0 release by the way if you guys didn't see that lane graph and lang chain has their like official 1.0 release like as in just a few days ago which is super cool i think it's a lot more robust for things like human in the loop and state persistence things that pidentic i might catch up with at some point for their multi-agent graph library,

[01:28:55 - 01:28:57]  but I don't think it's like a huge focus for them.

[01:28:57 - 01:29:00]  I mean, like Lane Graph is like all about multi-agent.

[01:29:00 - 01:29:03]  And then like that's just like a subset of Pidentica AI, right?

[01:29:03 - 01:29:06]  So it's just a matter of like Lane Graph is more specialized in that.

[01:29:06 - 01:29:09]  So I feel like they are probably always going to do it better.

[01:29:12 - 01:29:14]  Yeah, let's see where we're at in the implementation here.

[01:29:15 - 01:30:10]  Curious if we can, because I want to move on to the okay so we're doing the validation now got it okay so we're almost there and maybe like we can validate things kind of at the same time as AI so it's creating the unit tests for the rag pipeline right now which is cool so if we go back to our con we are at the very end here we still have to do our database setup but other than that like we have the validation and linting we're just currently going through all that so that's why everything's in the review stage right now. And then it'll be moved into the done stage, obviously, once we have the testing done, probably on our end as well. So we'll do the manual testing. Actually, we can do that right now. I'm really curious if I could just let it rip, let the rag pipeline rip. So let's see what we have. And again, for the sake of brevity, I'm not going to spend that much time doing a code review right now. I would highly recommend not vibe coding. I would highly recommend not vibe coding.

[01:30:10 - 01:30:15]  I would highly recommend going through and seeing what's created, what's changed, getting

[01:30:15 - 01:30:22]  a sense of the decisions that the coding assistant made when it was writing the actual code.

[01:30:22 - 01:30:25]  But I just want to look at this really quick.

[01:30:25 - 01:30:27]  For example, the chunking service.

[01:30:27 - 01:30:29]  Let's look at the chunking service.

[01:30:29 - 01:31:07]  I just want to make sure that it's using dockling correctly. Let's see. Okay, decisions are okay. I don't know what this tokenizer map is, because that seems a little rigid to me. But anyway, I'll try setting it up in a second here. And where is the dockling stuff? Hello? Let me search for dockling. Let me search for Dockling. It better have incorporated Dockling.

[01:31:07 - 01:31:09]  Um...

[01:31:09 - 01:31:15]  Wait a second. Oh, Dockling... wait a second.

[01:31:15 - 01:31:17]  Wait...

[01:31:17 - 01:31:25]  Did it not? Where is this... is this...

[01:31:25 - 01:31:30]  It didn't do anything with Dockling. That like it it totally dropped the ball here unless i'm missing

[01:31:30 - 01:31:38]  something big hold on i think it just made a terrible mistake where let me let me go back here

[01:31:38 - 01:31:47]  because do i do i call out dockling in my plan here i do but then if i search through my codebase

[01:31:47 - 01:32:20]  for dockling it uh literally only has the example here. Yeah, I did try with CK. I didn't find it. I think it like, you know what? I should have made my plan shorter. It's probably my fault for leaving the plan at 2,000 lines because I think it totally hallucinated that. It doesn't seem to be using dockling for rag at all. Like, that's stupid. Come on. Like, what is it doing for chunking here? Wow. Oh, less Um, wow.

[01:32:21 - 01:32:26]  Lesson learned, I try it because, I mean, obviously I wouldn't keep it as a 2000 line plan for real,

[01:32:26 - 01:32:29]  but I was just trying to go fast for you guys so you can get through everything.

[01:32:29 - 01:32:32]  But that is like a live lesson for you guys.

[01:32:33 - 01:32:37]  Why it is so important to make sure that you're not overengineering your plans or your code

[01:32:37 - 01:32:40]  because it just leads to these problems where it completely misses things.

[01:32:40 - 01:32:43]  That is like stated extremely explicitly in the plan.

[01:32:43 - 01:33:14]  Like if I search for dockling in the plan, let me open up the markdown again, because I guess you can't search in an overview. Like if I search for Dockling here, like boom, it's into my dependencies. And then here, like we're doing Dockling hybrid chunking based on the example. Like we literally have that and it just ignored it completely. So yeah, make sure that your plans are not 2,000 lines long because I'm going to have to go and correct it now. I mean, like, in the end, this is going to actually take more time than if I just went and had the plan correct and concise

[01:33:14 - 01:33:15]  from the get-go.

[01:33:17 - 01:33:23]  So, yeah, but I'll still try to run it right now and then correct that later, but it is a very good

[01:33:23 - 01:33:24]  lesson.

[01:33:25 - 01:33:29]  So let me open up the read-me because it will have documented how to run things as well.

[01:33:30 - 01:33:35]  So go ahead and do a UV-sync.

[01:33:35 - 01:33:39]  So I'll just follow its instructions.

[01:33:40 - 01:33:40]  All right.

[01:33:44 - 01:33:44]  And then I need to, let me start the environment.

[01:33:46 - 01:33:48]  VNV scripts activate.

[01:33:49 - 01:33:49]  Clear it.

[01:33:49 - 01:33:49]  All right.

[01:33:51 - 01:33:51]  And then I need to create my environment variables.

[01:33:52 - 01:33:54]  So what do I got here?

[01:33:57 - 01:33:57]  It wants my SuperData API, channel ID,

[01:34:00 - 01:34:03]  and then it wants my things for my embedding model, which looks good, my SuperBase configuration,

[01:34:03 - 01:34:33]  and my agent configuration, which I don't need this right now, so I don't really know why it created that either. But that's all good. And then I can specify a minimum and maximum chunks, which defaults to the 400,000 that I specified. So, like, clearly it got a lot of my instructions, right? Like, it didn't totally botch everything. Like, even the little details like this, it got. But it's just the dock link stuff specifically that it must have, for some reason, made a decision somewhere in here. And I wasn't looking because I was busy talking to you guys, which, I mean, it's worth it, right?

[01:34:33 - 01:34:34]  Like, we'll correct it.

[01:34:34 - 01:34:35]  We got it.

[01:34:35 - 01:34:39]  But somewhere I made a decision here to not use Dockling for some reason, even though it was in the plan.

[01:34:39 - 01:34:40]  Because it read the whole plan.

[01:34:40 - 01:34:41]  Like, we know it did.

[01:34:41 - 01:34:42]  It clearly did.

[01:34:42 - 01:34:44]  But yeah, let me go ahead and copy this.

[01:34:46 - 01:34:46]  Paste it here.

[01:34:48 - 01:34:50]  And rename it to .env.

[01:34:51 - 01:34:59]  So for my YouTube channel ID, I just need to go to my channel on another browser here.

[01:35:00 - 01:35:01]  Or actually, hold on.

[01:35:02 - 01:35:04]  I kind of forgot how to get a channel ID.

[01:35:04 - 01:35:09]  Because if I just go like this, it is just like at Colmedine.

[01:35:10 - 01:35:14]  So let me search how to get channel ID YouTube.

[01:35:15 - 01:35:17]  Go to settings on your YouTube account.

[01:35:19 - 01:35:20]  Navigate to Advanced.

[01:35:20 - 01:35:21]  Okay.

[01:35:21 - 01:35:23]  Well, I'll try to do this really quick.

[01:35:24 - 01:35:28]  Go to settings on my account, customized channel.

[01:35:29 - 01:35:32]  Oh, here we go. Okay. All right, this is my channel ID.

[01:35:33 - 01:35:36]  All right. And so we'll go seven days back.

[01:35:36 - 01:35:39]  One for max retries, five for batch size. It looks good.

[01:35:39 - 01:35:44]  I'll need my Super Data API key, which I will set that off camera, obviously.

[01:35:45 - 01:36:52]  And then I will need my credentials for OpenAI and Superbase as well. So, okay, for these things, I'm going to set them off camera, obviously. Don't want to expose that. So let me pull this up. And I'll have to bring this off camera as well, because I'll grab my Super Data API. Well, I guess I can just show this. I just grabbed it right here. So Super Data API, set that. Boom. And then I need my API key for open AI all right almost got that boom boom I'll leave the model as text embedding three small that works for me and then for my database here date API project URL copy that and then for my key I will reveal and

[01:36:52 - 01:37:03]  copy that boom okay good okay wish I could show you guys that but this is the one thing that's like

[01:37:03 - 01:37:10]  kind of awkward I have to do off camera but yeah all right I got everything set close that out go back

[01:37:10 - 01:37:16]  to the read me here and so now it'll process videos from the last seven days if I run this command

[01:37:16 - 01:37:22]  right here so apparently this is the moment of truth I don't have a ton of faith in it right now

[01:37:22 - 01:37:27]  because I skip through the the planning phase too quickly but let's see what happens I really hope

[01:37:27 - 01:37:59]  that this works all right so back in the terminal here, let's go ahead and kick this off. And hopefully I don't just get like an error immediately, so there's at least something to show. Oh, I don't have my database tables created yet. So that's going to be a problem. Also, it says that the SupaBase URL is required, but I do have that set. Superbase URL.

[01:38:00 - 01:38:03]  Okay, so it's a, I needs to fix that as well.

[01:38:04 - 01:38:07]  But yeah, it never actually created things in the database yet.

[01:38:07 - 01:38:14]  So that's another thing where I guess I can't really validate it yet because it's still in the middle of creating the database for me.

[01:38:14 - 01:38:17]  So, all right, let me go ahead and paste in this error.

[01:38:18 - 01:38:26]  Even though I have the .emb set, also you need to create the SQL for me to build the database tables.

[01:38:26 - 01:38:28]  All right.

[01:38:28 - 01:38:30]  Yeah, man, it's missing a lot of things here.

[01:38:30 - 01:38:31]  Because that's another problem.

[01:38:31 - 01:38:35]  When your plan is too long, it picks and chooses what it does.

[01:38:35 - 01:38:39]  And it doesn't do things like define the SQL for the database.

[01:38:39 - 01:38:44]  And, um, like it's not even loading in the environment variables,

[01:38:44 - 01:38:46]  environment variables apparently.

[01:38:46 - 01:39:18]  Like all of these problems with my typical system for AI coding that I just tried to simplify and go through fast here, like it would have knocked those things out. But it's just because I'm going quickly that it's messing up. So yeah, again, lesson learn. But yeah, while it goes and fixes this here, I'll go back into the chat here and just keep having a good time with you guys. While ClaudeCode works hard away for me. What is the best free coding model right now? Yeah, using the Gemini CLI with their like a really generous rate

[01:39:18 - 01:39:24]  limits is the best right now, I would say. Yep. And then if like I know it's not free, but like

[01:39:24 - 01:39:28]  Codex with like the $20 month plan gets you really, really far. So I'd recommend that too.

[01:39:32 - 01:39:40]  The plan had a dock link service. It did. Yeah, yeah, it totally missed it. It's felt it wrong in the plan.

[01:39:41 - 01:39:45]  I mean, it honestly might be be i don't think that incorrect spelling is what caused the problem

[01:39:45 - 01:39:50]  in the end because it would like realize that like the spelling's incorrect and it's still like no like

[01:39:50 - 01:39:57]  okay i should be using this external library to build in the hybrid chunking so i i think it's pretty

[01:39:57 - 01:41:52]  nuts like it's actually crazy what a plan that's too long can end up leading to as far as hallucinations It would be really cool if Cole could shed some light on the above-mentioned concepts are relevant or just fluff. If you tell me what concepts you're referring to, I can definitely answer. I'm looking through the chat. I don't see anything else. But yeah, I've noticed that some MCP servers and skills really chew up tokens. Usually those are the code review and testing agents. Pay attention to these if you're using the lower limit Claude code plans. Yep, 100%. Yeah, and that's kind of part of like context engineering is how can you create commands, like slash commands and sub agents in a way where they don't go for too long, right? Like being very explicit in your instructions set to like do simple validation or do simple analysis or simple review because otherwise they're just going to go on for forever right so yeah okay cool we got our migrations with our database script here so we got our channels and videos so like this is this is exactly what we have in the plan um so this looks really good so i'm going to go ahead and copy in yeah like it's basing it i can I can tell just in the way that's creating policies and things that it is also following what I have in my examples here, like in this file right here. So that, this is really good. Like, it's disappointed in some ways because my plan is too long, but like overall it's decent. So I'm going to go into my SQL editor here in Superbase, create a new snippet and paste this in. Whoops, I didn't actually copy it. So I just have my error message. There we go. Pace this in and run it. And let's see if it works first try. There we go. Okay, nice. So now going to my tables, I've got channels, transcript chunks, and videos. Nice. So looking really good. So the database is set up. And now we can see a moment of truth if we are able to run this thing. I would be pretty happy if it worked first try. And then we can always add in the dock link stuff later.

[01:41:53 - 01:42:44]  Okay. And then we can always add in the dock link stuff later. Okay, so we got our logging. This might be a little too verbose. Let's see, so the channel, oh, okay, so it's expecting the channel to already be here. So I guess maybe I just need to add that. Ah, yeah, that makes sense. So I need to add my channel explicitly, and then it'll work. So name, I'll do Colmedeen, that URL.

[01:42:46 - 01:42:47]  I'll do it like this.

[01:42:48 - 01:42:51]  Active, true, created at, good, good, save.

[01:42:51 - 01:42:52]  Okay, nice.

[01:42:52 - 01:42:54]  So that makes sense.

[01:42:54 - 01:42:57]  Like, I shouldn't expect my RAG pipeline to, like,

[01:42:57 - 01:42:59]  create the record for my channel.

[01:42:59 - 01:43:01]  So now let me go ahead and run this.

[01:43:02 - 01:43:03]  And then we should be good.

[01:43:04 - 01:43:05]  So we're making progress.

[01:43:05 - 01:43:07]  Making good progress.

[01:44:06 - 01:44:13]  Okay. Okay, there's one error that we got. It looks like that's repeating quite a bit. So, but this is good. An error is an opportunity for me to also teach you how I handle errors. And so it's retrying like over and over and again, which is also not good. So two things that we want to correct here. So I'm going to interrupt it. I'm going to copy this error. And I'm going to paste it in. And so here's kind of like the lesson that I want to give with this. Hold on. My live stream just crashed. I got to make sure I'm still live. Because my web browser just crashed. I think I'm good, though. Okay. All right, so the lesson that I want to give with this is that when you encounter a problem with your AI coding assistant, like it messes up something in the code, It's your job to figure out how drastically incorrect it is. For something little like this error right here, this is pretty small. At least I'm pretty confident that it's small.

[01:44:14 - 01:44:19]  And so I'm just going to, you know, very simply paste in the error and ask it to correct it.

[01:44:19 - 01:44:25]  If it was something really big, like honestly, it completely skipping dockling might honestly warrant this.

[01:44:25 - 01:44:28]  I would actually like go back to the planning phase

[01:44:28 - 01:44:29]  of the PIV loop, right?

[01:44:29 - 01:44:32]  So I'll pull this up for a visual again.

[01:44:32 - 01:44:35]  So like we're right here in the validation phase

[01:44:35 - 01:44:37]  and we realize that it completely messed up

[01:44:37 - 01:44:39]  something in the implementation phase.

[01:44:39 - 01:44:43]  So our two options is one, we can either just like

[01:44:43 - 01:44:45]  stay in validation and ask it to fix something

[01:44:45 - 01:44:47]  or we can go all the way back to planning

[01:44:47 - 01:44:50]  and correct our plan.

[01:44:50 - 01:44:51]  And then based on that correction,

[01:44:51 - 01:44:53]  have it try to re-implement things.

[01:44:53 - 01:44:57]  Like I could literally go into my source control here and I could wipe everything,

[01:44:57 - 01:45:02]  start from scratch with the plan and have it retry. Maybe after I fix something in the plan,

[01:45:03 - 01:45:07]  like maybe in my plan I need to make it much more concise. And then I also need it to be very

[01:45:07 - 01:45:13]  clear that like you should be using dockling for your hybrid chunking. Do not skip dockling for

[01:45:13 - 01:45:18]  the chunking strategy. Right. Like I could add that into the plan and then go back into validation.

[01:45:18 - 01:46:15]  I'm not going to show that right now for the sake of speed, but sometimes it's worth doing that if you realize through your code review and manual testing that it really screwed the pooch on this one. And it kind of, I mean, it did in some ways. We're going to make it work. We're going to make it work. But I think that's a good lesson to show here. And so let me go back to the code and just have it fix this here. So please fix this error. Also, when it was getting this error, it was retrying infinitely. It should also just retry a single time so address both of those things give me a very concise summary of of what you had to do to fix both right and so also adding that sentence in at the end because i want to be a part of the validation here because again going back to the diagram here the implementation is where we delegate to a i but then for both the planning and validation we want to be very in the loop i want to be very in tune with what we're planning and how things are actually going

[01:46:15 - 01:46:21]  in the implementation when we get to validation. And these are the kinds of things like,

[01:46:21 - 01:46:26]  like I keep telling you guys here that like I'm going over something quickly for just the sake

[01:46:26 - 01:46:30]  of brevity in the stream. Like I keep saying that over and over again because like we are already

[01:46:30 - 01:46:35]  an hour and 45 minutes into the stream. Like it takes a while to get to that point where we have

[01:46:35 - 01:46:39]  like a completed code and we have gone through the PIV loop.

[01:46:39 - 01:46:41]  And so again, just calling this out again,

[01:46:41 - 01:46:44]  like if you are really interested in going really deep

[01:46:44 - 01:46:47]  into these concepts, like that is what Dynamis is for

[01:46:47 - 01:46:49]  in the new Agentic Coding course,

[01:46:49 - 01:46:51]  because in the Agenic Coding course,

[01:46:51 - 01:46:54]  that is where I don't skip through anything.

[01:46:54 - 01:46:56]  And as we go through the mental models

[01:46:56 - 01:47:00]  and the PIV loop and how to start to build our systems

[01:47:00 - 01:47:03]  that are specific and optimized to your code bases,

[01:47:03 - 01:47:32]  how we can automate those systems and integrate them with our applications, even doing remote AI coding, leveraging out-of-the-box solutions like the PRP framework and BMAD. We're covering the whole landscape of AI coding here, and I'm not glossing over anything like I'm forced to do in something more concise like this. It's so much detail that I cover here. Like making sure that we don't have a plan that's 2,000 lines long, and I talk about what it looks like to shrink that. And even doing

[01:47:32 - 01:47:35]  like the same thing for global rules because we want global rules to be concise as well.

[01:47:35 - 01:47:40]  And that's one of like the big lessons for you guys to get out of this just in general is like

[01:47:40 - 01:47:47]  everything should be simple, concise because LLMs love to be over-engineering and they love to

[01:47:47 - 01:47:52]  just talk, talk, talk, talk in their plans like you guys saw and they just like to charge ahead.

[01:47:52 - 01:48:50]  And so one of the big things about building reliable and repeatable systems is that you want to do it in a way where it is focused on simplicity first. It's just so important to focus on simplicity first. So yeah, let's see, I got a, my chat didn't pop out. Hold on. Let me try one thing again. So my stream like crashed on me so let me try putting this in the chat again and seeing if that shows up well like stream didn't crash on me but my browser did so okay now i can show this yeah so all right yeah if you're interested in enjoying dynamist there's the link and the cozy you can use to get a discount on the monthly and the yearly so hope to see you inside for the course and everything else we have in dynamist so yeah with that let's head back over to...

[01:48:50 - 01:48:51]  Alright, good.

[01:48:51 - 01:48:52]  So, fix both issues.

[01:48:52 - 01:48:53]  Type error.

[01:48:53 - 01:48:56]  Super Data returns objects, not dictionaries.

[01:48:56 - 01:48:58]  Okay, makes sense.

[01:48:58 - 01:49:01]  And then infinite retries.

[01:49:01 - 01:49:03]  Okay, good.

[01:49:03 - 01:49:04]  So I made an adjustment there.

[01:49:04 - 01:49:05]  Looks really good.

[01:49:05 - 01:49:07]  So we can actually try this again.

[01:49:07 - 01:49:09]  Hopefully it'll work better this time.

[01:49:09 - 01:49:11]  My goal here is just to have something show up

[01:49:11 - 01:49:40]  in the transcript chunks and videos tables. Like that, that's the goal that I've got so let's see okay it failed again well that's fun I guess we get to iterate more I was hoping not to iterate too much but that's the nature of of AI coding sometimes you just have to do it because I think what I want to do is just ask it to let's see getting this error now I want to just make the validation very simple.

[01:49:40 - 01:49:42]  I think you're over-engineering this right now.

[01:49:43 - 01:49:44]  Just not need it to be simple.

[01:49:44 - 01:49:45]  I need it to work.

[01:49:47 - 01:49:49]  That was maybe a little silly, but yeah,

[01:49:49 - 01:49:53]  and then the infinite retrys was still happening.

[01:49:53 - 01:49:55]  All right, not spelling it correctly entirely,

[01:49:56 - 01:49:56]  but that's totally fine.

[01:50:01 - 01:50:02]  All right, greeting champs,

[01:50:02 - 01:50:04]  carried a guy to loss muggle, non-techie.

[01:50:04 - 01:50:32]  Does coding specific models help in task other than coding? Example, obsidian related. Moreover, can someone check how legit Lemon AI agent is? I'm not familiar with Lemon AI agent. I've got no idea. But to your other question, though, for AI coding models, they do definitely help with other things related to file management. Because, like, coding LLMs are specialized, not just on writing code, but like handling files, right? Like moving files, creating files, editing files.

[01:50:32 - 01:50:36]  And so there's something like a Biscidian where it is just like file management, they

[01:50:36 - 01:50:39]  definitely shine with that and more like instruction following as well.

[01:50:39 - 01:50:41]  So yeah, 100%.

[01:50:41 - 01:50:42]  That's a good question.

[01:50:47 - 01:50:50]  Colmanine has a true open source mindset.

[01:50:50 - 01:50:53]  The community is private and pay to play, but his tools are free and available on GitHub.

[01:50:53 - 01:50:55]  Yeah, I appreciate that.

[01:50:55 - 01:50:56]  I hope that helps.

[01:50:56 - 01:51:02]  Yeah, so yeah, the answer to your question is does the course use your

[01:51:02 - 01:51:07]  software must be used it the answer is no so when I talk about my open source

[01:51:07 - 01:51:12]  projects like Arcon or I've covered like my PRP framework a lot before that

[01:51:12 - 01:51:17]  Rasmus built and like we've showcased on my channel a lot like I have my specific

[01:51:17 - 01:51:23]  strategies for AI coding but the course itself doesn't cover those more opinionated

[01:51:23 - 01:52:16]  things until the end of the course and so very intentionally I'm starting from the ground up to help you define your own systems so you're not reliant on my tools I talk about how you can use them but more importantly I show you like how you can build your own system regardless of the tools in the AI coding assistant that you're using so really good question not limited to my stuff like I never want to just like push my stuff on you I want it to be a resource that you can leverage when you want but you never need to to like get the most out of like what I'm covering like I'm using Arcon in this live stream because it's a fantastic tool but also you could definitely just like have it search the web for Super Data instead of using the Super Beta Docs in Arcon or you could have it manage its own internal tasks instead of using Arcon for that right like all those things it's never a requirement to use Arcon as an example so all right let's try this out here.

[01:52:45 - 01:52:46]  Yes, you're very welcome, Stephen. All right. Okay, I think it's actually working really well now. Let's go. All right, finally. Our rag pipeline is in business. Let's go. Let's check the, let's yep, looking really good.

[01:52:48 - 01:52:51]  And then transcript chunks.

[01:52:52 - 01:52:54]  Okay, nice. So let's validate one of these.

[01:52:54 - 01:52:56]  I'm gonna check this video.

[01:52:56 - 01:52:59]  The only problem I have is it feels like it went,

[01:52:59 - 01:53:02]  it's going longer than one week.

[01:53:02 - 01:53:04]  So I think that is bad.

[01:53:04 - 01:53:07]  Like how, okay, this is, see this is two weeks old.

[01:53:07 - 01:54:53]  So, okay, things are working almost. It's just, like, not respecting the fact that I only want to go one week out. So I'm going to cut this short here. But it's working now. Like, we're making good progress. And a lot of this iteration, I want to be very clear, I probably wouldn't have to have done if I was a lot more explicit and concise in my planning. I'm going to say that over and over again because I honestly regret not spending more time with that with you guys here. Because we probably would have gotten to where we are now, but it's just a better planning document and like the same amount of time at this point. But you know, hindsight, 2020, I've never built an agent live with you guys, so that's part of what I have to learn as well, just as I'm doing it here. So I appreciate your guys' understanding as I'm doing this. But yeah, it looks like it went really far. Like if I go to this video now, which one is this? Welcome to the Arcon. Arcon Beta Launch Live stream. This is from two months ago. Okay, so not what I wanted it to do, but it is kind of cool that like, that was actually pretty quick to get the transcripts pulled and embedded and inserted into my knowledge base for the last two months worth of videos. Like, that is pretty neat. So, okay, but I'll just go into the coding assistant and say, everything is working great now. However, it pulled videos from like even two months ago, like 20, 30 videos when it should have just done the last couple from the last week. And so it definitely is not respecting the day limit that we have set in the environment variables right now. Boom. All right. So we're almost there. And then honestly, in the meantime, I can, and thanks for the kind words, David, and Frosty Frog. I appreciate it, guys. Yeah. Do my best. I mean, this is like super fun. Like, I'm having a blast with you guys, even though it's like

[01:54:53 - 01:54:57]  a little bit of scrambling in my mind trying to figure out like, okay, how fast should I go over

[01:54:57 - 01:55:01]  is how comprehensive should I be? That's always a challenge with these live streams. But yeah,

[01:55:01 - 01:55:06]  while this is going here, I'm going to actually open up another Claude instance in parallel

[01:55:06 - 01:55:12]  because I want to do the implementation for the agent now. And since I've already covered the

[01:55:12 - 01:55:19]  PIV loop and we already have our considerations here, well, I guess we don't have it for this one.

[01:55:19 - 01:55:22]  I'm going to go through this one a lot faster now, right?

[01:55:22 - 01:55:24]  Because I already went through the full PIV loop with you guys.

[01:55:24 - 01:55:26]  And we talked about the commands.

[01:55:26 - 01:55:27]  We talked about Arcon.

[01:55:27 - 01:55:31]  We talked about how we are going through the vibe planning.

[01:55:31 - 01:55:33]  I'm going to go through this one a lot quicker now.

[01:55:33 - 01:55:35]  And it also should be simpler because we already

[01:55:35 - 01:55:37]  have the core part of our code based setup

[01:55:37 - 01:55:39]  and like our database tables and everything.

[01:55:39 - 01:55:42]  And so now I'm going to go into a parallel session

[01:55:42 - 01:55:46]  while the other thing is still fixing some stuff for the RAG pipeline.

[01:55:47 - 01:55:48]  And let's go ahead and knock out the agent.

[01:55:49 - 01:55:53]  And so I'm just going to say, well, first of all, I'm going to do the slash primer.

[01:55:53 - 01:55:57]  So I'm going to prime the coding assistant on my code base.

[01:55:57 - 01:55:59]  Well, you know what?

[01:55:59 - 01:56:01]  I need to fix up this primer here.

[01:56:01 - 01:56:04]  Read the key files in source.

[01:56:06 - 01:56:06]  There we go.

[01:56:07 - 01:56:10]  Cool, because I didn't have that customized this code base yet.

[01:56:10 - 01:56:12]  So I'm gonna go back into Claude.

[01:56:12 - 01:56:14]  Again, just going a little bit quicker here.

[01:56:14 - 01:56:17]  So you guys get to see a speed run.

[01:56:19 - 01:56:22]  So, all right, slash primer.

[01:56:22 - 01:56:23]  All right, so I'm gonna do a primer now.

[01:56:23 - 01:56:27]  So I talked about the primer just a little bit earlier,

[01:56:27 - 01:56:30]  but it's a command to just instruct it very simply

[01:56:30 - 01:56:32]  and like, here's what I want you to read through

[01:56:32 - 01:56:34]  and understand so that you're caught up to speed

[01:56:34 - 01:56:35]  on the code base, right?

[01:56:35 - 01:56:37]  Because we started a brand new conversation,

[01:56:37 - 01:56:39]  but I wanted to understand what I already have in my code base

[01:56:39 - 01:56:42]  as I go into planning for the next feature.

[01:56:42 - 01:56:45]  So I'm gonna let the primer run, and then while it runs,

[01:56:45 - 01:56:47]  I'm gonna go in and let's just do some planning

[01:56:47 - 01:56:49]  for our agent here.

[01:56:49 - 01:56:51]  So I'm gonna go ahead and delete these two things

[01:56:51 - 01:56:53]  because we're not working on that right now.

[01:56:53 - 01:56:55]  I wish I had time to get into other things

[01:56:55 - 01:56:57]  like observability, but definitely won't.

[01:56:57 - 01:57:00]  So I'm gonna say building a RAG agent

[01:57:00 - 01:57:30]  to search my YouTube knowledge base. And so the tech stack here is going to be Python, Pidentic AI, and Supabase, right? And then for other considerations here, we need to be able to specify the LLM provider and model in .e and B, like in the examples folder. Right? So we have that one of those things in the examples folder already. I'll say we want a rag tool to search chunks

[01:57:30 - 01:57:34]  and a rag tool to read an entire transcript.

[01:57:34 - 01:57:36]  And so transcripts are short enough

[01:57:36 - 01:57:39]  where they can definitely fit in the context for an LLM.

[01:57:39 - 01:57:42]  And so if we find a chunk for a transcript

[01:57:42 - 01:57:44]  and the agent decides like, oh, I actually wanna read

[01:57:44 - 01:57:47]  the full transcript, I wanna give it a tool

[01:57:47 - 01:57:47]  to be able to do that.

[01:57:47 - 01:57:50]  Like that's kind of the agentic rag piece

[01:57:50 - 01:57:53]  that at least in a simple starting sense

[01:57:53 - 01:58:51]  will give our agent the ability to search our knowledge base in different ways and make it more adaptable. So it can actually think to itself, I want to read the entire transcript, not just focus on that little segment because maybe the user's question is more overarching. So I'll do that. And then I'll say we need to use the match function in the dot SQL file for the RAG search tool. What other consideration? Maybe you guys can share with me in the chat what kind of other considerations you think we should have for building this pedantic AI agent that can search our knowledge base. And, Bo, the tool that I used to fetch YouTube transcripts is called Supa Data. Super Data. It's this one right here. Very, very affordable. And then you could also use the YouTube API directly if you wanted to

[01:58:52 - 01:58:57]  Only work with your own videos. I'm using super data because it's a way for me to crawl like any video from any channel

[01:58:58 - 01:59:04]  Which is very nice. Do we need a chunker? So we don't need a chunker here because we already took care of that in the rag pipeline

[01:59:04 - 01:59:07]  So right now we're just building the agent with the tools

[01:59:08 - 01:59:16]  to be able to search another thing that I can think of here is um we need a we need to build the agent

[01:59:16 - 01:59:23]  API exactly like agent API dot pi in the examples folder right so i'm calling out like we have

[01:59:23 - 01:59:31]  the example there and then i can even say like follow agent dot pi and tool dot pie to see how to

[01:59:32 - 01:59:42]  build tools um from the example folder right so like keep calling out like I said our cheat code

[01:59:42 - 01:59:46]  existing projects bring it into examples reference it have it look there to see

[01:59:46 - 01:59:49]  how we do things like setting up our database tables and our agents and our tools

[01:59:49 - 01:59:54]  like I want to keep leaning on that as much as I possibly can it's so important

[01:59:54 - 02:00:00]  maybe a limit to the size of the transcript I like that idea yeah a rag

[02:00:00 - 02:00:30]  tool for pulling transcript a limit transcript limit to a size specified in dot e and b right so like just in case we try to pull like an eight hour long YouTube video we could limit it and then like maybe even the tool would say like this has been limited because it's too long or something like that rag as in citation with timestamps and video ID I love that yeah rag tool to cite time stamps and video ID.

[02:00:30 - 02:00:34]  Well, even better, we could say to cite video URL

[02:00:34 - 02:00:39]  and timestamp, URL with timestamp even,

[02:00:39 - 02:00:41]  because there's a way to do that in YouTube

[02:00:41 - 02:00:44]  where you can have the timestamp be a part of the URL

[02:00:44 - 02:00:45]  so that when someone visits that link,

[02:00:45 - 02:00:47]  it takes them right to that time in the video.

[02:00:47 - 02:00:50]  So I think that's really good.

[02:00:50 - 02:00:52]  Cool, include citations, yeah, so Tony said it too.

[02:00:52 - 02:00:55]  Love that, yeah, I definitely should not be missing that

[02:00:55 - 02:01:25]  in my considerations. So I think this is good this is good to start so I'm going to copy this go back in first of all for our other instance of cloud code we are now only going back to seven days so that's good so now within here it has primed itself so we finished the priming so now the coding assistant understands our current project and so I'm going to paste in, just like I did before, the other considerations, and I'm going to speak to it again.

[02:01:25 - 02:01:28]  So right now this project only has the RAG pipeline.

[02:01:28 - 02:01:30]  Now I want to build the PIDantic AI agent.

[02:01:30 - 02:01:33]  So take in all the considerations that I have specified above.

[02:01:33 - 02:01:43]  I'm going to be using, again, Python, Pidentic AI for the framework, and Supabase, obviously, to reference the knowledge that we're storing from the RAG pipeline.

[02:01:43 - 02:03:06]  I also, by the way, have the documentation for PIDantic AI available in ARCON for you to search. So take a look at that right here. All right. Then I also want you to reference quite a few files that we have in the PRPs examples folder. And so within backend underscore agent underscore API, we have agent underscore API and agent. dot pie as well as tools. I want you to read all three of these files in entirety because I want to create the Pidentic AI agent in a very similar way. And this agent also leverages the environment variables that we have in the dot, e.mv.example file there, in the example. So I want you to take a look at that. This will give you a really holistic picture of how to build the agent to work with any LLM, how to build tools and the dock string for tools. And then the other really important thing here is that I want to copy what we have for the agent underscore API.P.I. Like pretty much exactly. I want to build the API endpoint in exactly the same way so I can use it with the same front end that I already have created. And I want this API to be probably a lot simpler than the one that we have in the examples. Like I don't need anything with Mem Zero that I have in there right now.

[02:03:08 - 02:03:12]  But yeah, I definitely want to have the same structure. And you can literally copy the DB underscore Utills

[02:03:12 - 02:03:14]  that we have in this example folder.

[02:03:14 - 02:03:16]  You can copy that and use that exactly

[02:03:16 - 02:03:18]  because I have all the functions here

[02:03:18 - 02:03:20]  to manage the conversations and messages

[02:03:20 - 02:03:22]  in the Superbase table already.

[02:03:22 - 02:03:24]  But then just make sure that you add the tables

[02:03:24 - 02:03:28]  that we have from rag underscore agent underscore tables.seq.

[02:03:28 - 02:03:30]  Make sure you add the messages and conversation

[02:03:30 - 02:03:59]  and requests and all of that to the primary SQL that we have in our migrations folder here. And so yeah, right now I want you to explore all these files and help me come up with a plan of my different options. Don't implement any code yet. Okay, that ended up being way more than I thought it was going to be. But just as I was talking, I was realizing all the different things I wanted to incorporate from my example. And I'm going fast here. I know there's like a lot of different things that I'm referencing from my previous project.

[02:03:59 - 02:04:02]  But yeah, like I want to like have it work explicitly

[02:04:02 - 02:04:04]  so that it can be leveraged immediately

[02:04:04 - 02:04:07]  within the website that I have here.

[02:04:07 - 02:04:10]  And so yeah, I'll let it go and I'll see.

[02:04:10 - 02:04:12]  And like this time I'm also gonna tell it

[02:04:12 - 02:04:14]  to create a lot simpler of a plan.

[02:04:14 - 02:04:16]  And so hopefully this will give you guys

[02:04:16 - 02:04:18]  a nice demonstration of how things look a lot different

[02:04:18 - 02:04:20]  when we do have a simple plan.

[02:04:20 - 02:04:22]  And things aren't over-engineered

[02:04:22 - 02:04:24]  because Claude likes to talk, talk, talk.

[02:04:26 - 02:04:27]  So, all right.

[02:04:28 - 02:04:29]  Context window exhausted.

[02:04:29 - 02:04:30]  Well, this is a brand new context.

[02:04:31 - 02:04:33]  And even with all the talking that I did here,

[02:04:33 - 02:04:35]  like, it's not that bad overall.

[02:04:35 - 02:04:36]  Like, this is only a couple hundred tokens.

[02:04:37 - 02:04:39]  So I think we're good.

[02:04:39 - 02:04:42]  Because it costs a lot more tokens when it's reading files and things.

[02:04:46 - 02:04:56]  So, all right. Jay said, I always use big plans, but have a step-by-step plan.

[02:04:56 - 02:04:59]  Do step one, then step two, then no problems with forgetting things.

[02:04:59 - 02:05:00]  That's good.

[02:05:00 - 02:05:03]  Honestly, that's kind of what I was going for, but it still forgot things.

[02:05:03 - 02:05:04]  So I don't know.

[02:05:04 - 02:05:06]  It could have been more of a fluke, too.

[02:05:06 - 02:05:09]  It is pretty crazy that it ignored dockling.

[02:05:10 - 02:05:13]  Or maybe there's something that I'm missing, and it actually is leveraging in it,

[02:05:13 - 02:05:15]  but I think that it missed it, but oh well.

[02:05:42 - 02:05:43]  All right, cool. So it's searching the Rag Knowledge Base for Pidentic AI. That's looking really good. So it'll help create its plan as well. And so once this is done, then I'll run the create plan command. So all right. Yeah, so while this is going, one thing I want to say is the use case specifically, let me actually pull up.

[02:05:45 - 02:05:46]  I'm gonna pull up something else here.

[02:05:48 - 02:05:51]  Don't mind me, I'll go to the course introduction that I have for, so this is like the

[02:05:51 - 02:05:55]  Excaladra diagram that I have for the introduction

[02:05:55 - 02:05:57]  to the agentic coding course.

[02:05:58 - 02:06:01]  So let me put this in the chat again really quick.

[02:06:04 - 02:06:06]  So for the agentic coding course,

[02:06:06 - 02:06:07]  this is the introduction that I got.

[02:06:07 - 02:06:09]  And one of the things I to call it really quickly,

[02:06:09 - 02:06:14]  I think it's super neat, is when I show the principles

[02:06:14 - 02:06:19]  of AI coding and creating a full system around AI coding,

[02:06:19 - 02:06:22]  I'm not just doing it on like some random project.

[02:06:22 - 02:06:24]  I'm gonna scrap after the course is done.

[02:06:24 - 02:06:26]  I wanted to build something freaking awesome.

[02:06:26 - 02:06:28]  So not only do you like have the course

[02:06:28 - 02:06:29]  and like everything you learn from it

[02:06:29 - 02:06:32]  and the systems you build from it and the templates there,

[02:06:32 - 02:07:01]  but you also get a complete AI agent built as a part of the course. And the agent is the Obsidian Second Brain Assistant. So it's leveraging obviously Obsidian. And then a lot of like the same stack that we're covering in this stream right now, like with PIDAN-T-A-I for building out our agent, like that's the framework and super base for our database. And so it's an agent where like you can literally have it brainstorm based on your documents, help you organize your notes and knowledge and obsidian.

[02:07:01 - 02:07:04]  There's a lot of more tools that we're going to add as we go throughout the course,

[02:07:04 - 02:07:08]  like with the very full schedule that we have for the course over the next month.

[02:07:08 - 02:07:10]  Like, yeah, so it's a really awesome use case.

[02:07:10 - 02:07:15]  I just want to call it out explicitly because this is going to be like another really big resource

[02:07:15 - 02:07:16]  in the Dynamist community.

[02:07:16 - 02:07:20]  So again, if you're interested in taking your AI coding to the next level and you really

[02:07:20 - 02:07:25]  want to dive deep into some of the things I'm covering this stream, then yeah, definitely

[02:07:25 - 02:07:54]  check out Dynamist.a.i. And the codes that I have on the screen right now, those are going to go away right after the live stream. Like, this is your chance to get a discount that I'm not going to have for a long time again. So, yeah, 20% off the monthly and then 40% off the yearly membership. And you're getting the agent decoding course, the AI agent mastery course, the whole community, access to me every single day, and weekly workshops that I'm doing every Friday, which those are a blast as well. Like in the last

[02:07:54 - 02:08:02]  workshop, we covered Claude code or not cloud code. We covered Claude skills and plugins, like both

[02:08:02 - 02:08:06]  in one, some cool use cases that I've built out. So like we're always covering like the latest tech

[02:08:06 - 02:08:11]  and then using the workshops as a way to like dive deeper into like really specific things for

[02:08:11 - 02:08:15]  some of these concepts as well. And so I'm actually going to be doing workshops related to the

[02:08:15 - 02:08:20]  agentic coding course throughout the next month as we're releasing the batches.

[02:08:20 - 02:08:23]  And so I'll actually show you the schedule really quick.

[02:08:23 - 02:08:32]  So like we did a, we're doing a live workshop next Friday related to the first block that was released just for the course now.

[02:08:32 - 02:08:38]  And then like for the second release block, there's going to be another live workshop in a couple of weeks, like in a few weeks from now.

[02:08:38 - 02:08:40]  And then a third one and then a fourth one.

[02:08:40 - 02:08:45]  So it's almost like if you join right now, you kind of get to be a part of a cohort going through the course with me for the first time

[02:08:45 - 02:08:50]  with all these live events to make it even more interactive so yeah it's it's pretty exciting like

[02:08:50 - 02:08:55]  this is like the main thing that i'm working on right now um and it's been a blast and like a lot of

[02:08:55 - 02:09:02]  the things that we're we're building together here but just going that much deeper so yeah

[02:09:03 - 02:09:08]  all right is your course a live course or is a pre-recorded can we view it any time

[02:09:09 - 02:09:14]  yeah so good question stephen so. So it's all going to be pre-recorded and then we have the live

[02:09:14 - 02:09:20]  workshops that are going to be a part of each of those released batches, but the recordings of those

[02:09:20 - 02:09:25]  will also be posted after. So you can view it any time. It's meant to be a course that will

[02:09:25 - 02:09:29]  obviously stand the test of time because of the principles that I cover and like will be available

[02:09:29 - 02:09:33]  for you to to view forever. And then I'll evolve them over time. Like if there's ever anything

[02:09:33 - 02:09:38]  that becomes irrelevant to the material or like I've evolved my approach the course will evolve as well

[02:09:38 - 02:09:42]  it's the same thing with everything else and dynamists as I I work my butt off to keep it like

[02:09:42 - 02:09:46]  really up-to-date and making sure that like I said I always help you fight the fluff and just

[02:09:46 - 02:09:53]  like work with or like focus on what works right now right when is the first live course

[02:09:53 - 02:09:58]  starts so the first the first batch of the course is released it came out on Friday

[02:09:58 - 02:10:03]  and then the first workshop for the course

[02:10:03 - 02:10:04]  is going to be this Friday, right?

[02:10:04 - 02:10:06]  So like you have a week to like go through

[02:10:06 - 02:10:08]  the first few videos and then there's a couple

[02:10:08 - 02:10:10]  like exercises that we have there

[02:10:10 - 02:10:11]  and then you get to go into the workshop

[02:10:11 - 02:10:14]  where I cover my solution for the exercise.

[02:10:14 - 02:10:15]  And then later that'll just be like

[02:10:15 - 02:10:18]  another pre-recorded video basically in the course

[02:10:18 - 02:10:19]  is the way that I'm structuring it.

[02:10:19 - 02:10:21]  So it works either way.

[02:10:21 - 02:10:23]  But like joining right now is when you have the discount

[02:10:23 - 02:10:24]  during the live stream here.

[02:10:25 - 02:10:26]  So yeah.

[02:10:26 - 02:10:29]  All right, let's go back here.

[02:10:31 - 02:10:31]  All right, we have our plan.

[02:10:34 - 02:10:35]  So I'm not going to read through all of this right now.

[02:10:36 - 02:10:36]  Typically, I would.

[02:10:38 - 02:10:39]  So you heard me say that for the other plan as well.

[02:10:40 - 02:10:41]  But yeah.

[02:10:43 - 02:10:45]  So we're copying the exact structure of agent API.

[02:10:46 - 02:10:46]  Looks good.

[02:10:48 - 02:10:50]  So we're doing the same thing for authentication and rate limiting and conversation management.

[02:10:50 - 02:10:52]  This is like a super robust API that I created

[02:10:52 - 02:11:24]  as a part of the Dynamist AI agent mastery implementation. So it's recommending option one, minimal coach. So okay, looks good, creating our tables, updating our environment variable. We're creating only three tools. Like this, this is good. But I don't actually... Everything looks good. Option one is definitely what I want, but I don't want a tool for a format video citation.

[02:11:24 - 02:11:27]  Like that should just be deterministic code that's included right within the RAG tool.

[02:11:28 - 02:11:33]  Okay, otherwise, because, right, like, I don't really want it to call a separate tool just to format

[02:11:33 - 02:11:40]  things. Like, that's stupid, but everything else is looking really good. So API layer with authentication,

[02:11:40 - 02:11:44]  making sure it's testing everything. And then it's giving me a couple of options. And like,

[02:11:44 - 02:12:40]  I am just going to go with the most simple one right now because also that if I don't go with the most simple one it's just going to be overengineered like I can absolutely guarantee it so I'm going to send this in and then after it acknowledges that then I'm going to go ahead and create the plan so I'll just do create plan and I will say create a simple plan for the implementation of the agent based on our conversation Keep it between. I'm going to be explicit here, 500 and a thousand lines. Because, yeah, this is going to be better. And honestly, I should have done that for the other one. Also within the create plan. This is also an opportunity to evolve my system, right? Like, I could go in here and be like, you know, important. The plan should be between 500 and 1,000 lines. And maybe there's a lot more than I should do to like truly make this more elaborate, but like even a

[02:12:40 - 02:12:47]  simple addition like this is potentially all it takes to learn from what happened previously

[02:12:47 - 02:12:51]  and then fix it for the next implementation. I'm actually going to try this. I'm going to delete

[02:12:51 - 02:12:56]  this line because now I have that as a part of my plan. Well, actually that's not sure. I'd

[02:12:56 - 02:13:01]  have to reload Claude Cod code for this to take effect, so I'm just going to add it in right

[02:13:01 - 02:13:05]  here. But you get the idea. So keep it between 500 and 1,000 lines.

[02:13:06 - 02:13:07]  All right, there we go.

[02:13:07 - 02:13:10]  So it's going to create an AI agent with two simple tools.

[02:13:10 - 02:13:11]  Nice and basic.

[02:13:11 - 02:13:11]  I like that.

[02:13:12 - 02:13:14]  And then we already have our knowledge base set up.

[02:13:14 - 02:13:16]  And it's actually kind of nice that it has,

[02:13:16 - 02:13:18]  that it went way too far because now I have a lot of data

[02:13:18 - 02:13:20]  to search through with the agent here.

[02:13:20 - 02:13:22]  So we will see, we'll see if it works.

[02:13:24 - 02:13:25]  I'm going to let it rip again,

[02:13:25 - 02:13:27]  and I'll spend some more time in the chat

[02:13:27 - 02:13:35]  as we let it go.

[02:13:35 - 02:13:36]  All right.

[02:13:36 - 02:13:36]  You're good.

[02:13:37 - 02:13:37]  All good.

[02:13:38 - 02:13:38]  I know fat fingers happens.

[02:13:39 - 02:13:40]  No worries.

[02:13:41 - 02:13:41]  You're late, it seems.

[02:13:42 - 02:13:42]  Well, that's all good,

[02:13:44 - 02:13:46]  because the whole recording will be posted for the live stream after it's done.

[02:13:46 - 02:13:47]  I think it just takes a couple hours

[02:13:47 - 02:13:48]  for YouTube to process,

[02:13:49 - 02:13:49]  but you're all good.

[02:13:50 - 02:13:51]  Glad to have you here.

[02:13:52 - 02:13:52]  That's what matters.

[02:13:55 - 02:14:23]  Okay. Yep. Okay, so Steve, another good question. What happens if the plan must be longer than 1,000 lines, say 2,000? Do you have to do a two-part plan and you build each project separately and merge later? Yeah, so I honestly, I would say that if your plan has to be 2,000 lines, you're trying to do too much at once. Like I would try to, not like, make a two-part plan.

[02:14:23 - 02:14:26]  I would think of it more as like splitting your implementation

[02:14:26 - 02:14:28]  in two separate tasks entirely.

[02:14:28 - 02:14:31]  And then do the PIV loop for each of those.

[02:14:32 - 02:14:34]  And so you're not splitting up the plan,

[02:14:34 - 02:14:36]  you're going one level higher to like splitting up

[02:14:36 - 02:14:38]  the actual work that you need to do.

[02:14:40 - 02:14:43]  So yeah, I mean you could try to do 2,000 lines,

[02:14:43 - 02:14:46]  but you're probably going to run into the same thing that I did.

[02:14:46 - 02:14:50]  Maybe there's a way to optimize my, you know, execute command, for example, that would

[02:14:50 - 02:14:56]  have it like handle every, every task better, but I told it to do things task by task in a loop

[02:14:56 - 02:14:58]  and it still missed the dockling stuff.

[02:14:58 - 02:15:02]  So, yeah, I think just like you're doing too much at once if it has to be longer than

[02:15:02 - 02:15:06]  a thousand lines, and I'm going to have it do just 500 lines to 1,000 here.

[02:15:08 - 02:15:09]  Yep, you're very welcome.

[02:15:12 - 02:15:41]  I've done this exact thing for a local ray agent. That's cool, Stefan. What are you using to extract transcripts? So yeah, I'm using a tool called SupaData. That is my tool to get the job done here. And so I like SuperData because it works for more than just like my own videos. Like if I use the YouTube Data API, it only works for my own videos or ones that I have edit access to. And then also it avoids like rate limits and IP blocking and stuff that you can hit if you're using like a just like a Python library, for example, that just like crawls directly.

[02:15:41 - 02:15:44]  So they have like proxies and things built into the platform.

[02:15:44 - 02:15:46]  So it's pretty robust and production ready, I would say.

[02:15:47 - 02:15:47]  So I like it a lot.

[02:15:50 - 02:15:54]  Course amount is very high for poor countries where $1 equals 90 in their currency.

[02:15:54 - 02:15:55]  Yeah, I understand.

[02:15:55 - 02:15:59]  I wanted to bring this up really quick because I saw a couple of comments on that.

[02:16:00 - 02:16:05]  I do understand, but geographical price parity is something that I will have to look into more,

[02:16:05 - 02:17:00]  but like initially looking at it, like just in the platform, I don't think it's supported. And I think that really is the case, unfortunately, for most platforms, like school, circle, which is what I use. If you're using like WOP, I think it's called. Like, I don't think they support that. So, yeah. But, I mean, there are people in the community from all over the world. Like, we got a ton of people in Germany, people in Brazil. We got people in, like, Saudi Arabia, like Dubai. We got people from South Africa, Australia. Actually, so the United States has the most members. Probably not a surprise to anyone. And then Germany is second. And then Australia is third. So I track metrics for where everyone's at in the community. It's pretty cool. And you don't have to share your location. So it's just for the people I do. Like obviously there's no privacy issue. Like

[02:17:00 - 02:17:04]  you can be as secretive as you want when you're in the community. Like it's totally up to you.

[02:17:04 - 02:17:08]  But like for the people that share and I think it's cool that it'll just share like generally

[02:17:08 - 02:17:12]  their country or state or whatever. Like it's cool to see the stats around that. A lot of people

[02:17:12 - 02:17:18]  from Canada as well, of course. I think Canada's fourth. And then like the UK is fifth,

[02:17:18 - 02:17:21]  I believe. So yeah, it's pretty cool.

[02:17:23 - 02:17:25]  Yeah, I think Belgium Belgium sixth or something.

[02:17:25 - 02:17:31]  Um, I mean, I don't remember off the top of my head getting into those numbers, but yeah, it's pretty sweet.

[02:17:31 - 02:17:34]  So yeah, very global community and that, that's like super exciting to me.

[02:17:34 - 02:17:40]  Because there, there's people that are posting things and sharing things like every hour of the day because it's a global audience.

[02:17:41 - 02:17:45]  So I always like wake up to like, like five things where it's like, oh, that's super interesting.

[02:17:45 - 02:17:46]  Like every single day.

[02:17:47 - 02:17:47]  It's pretty cool.

[02:17:48 - 02:17:52]  So, yeah.

[02:17:54 - 02:17:55]  There's so much free stuff on YouTube from Cole and others. Yeah, that's right.

[02:17:55 - 02:18:01]  Yeah, I'm like, I talk about my community and my course a lot today because that is like the forefront

[02:18:01 - 02:18:02]  of my mind.

[02:18:02 - 02:18:03]  Like it just came out.

[02:18:03 - 02:18:07]  But like 100%, like I'm always going to be giving a ton of free stuff on YouTube as well.

[02:18:07 - 02:18:08]  That's never going to go away.

[02:18:08 - 02:18:13]  Like my ethos is always going to be open source and just like giving a ton of value through

[02:18:13 - 02:18:14]  the content on my channel.

[02:18:14 - 02:18:18]  But the community is just a place to go deeper. i think that's like a good way to put it and to

[02:18:18 - 02:18:24]  cover the things that like i don't have the ability to like even if i wanted to i can't go through

[02:18:24 - 02:18:29]  my whole process in the stream today in a lot of detail because i'm going to lose my voice like i

[02:18:29 - 02:18:33]  already feel like i'm going to lose it pretty soon and i think it is going to be time to wrap up

[02:18:33 - 02:18:38]  the stream pretty soon here i just want to try to knock out this plan and hopefully see the agent

[02:18:38 - 02:19:09]  in action and then um call it good there. So, yeah. You're doing a good job, learned a lot from me. I appreciate that. Thank you, Stefan. That means a lot. Great response. Yeah, thank you, Mark. Cool. Steven, thank you. Favorite AI coder to follow online, bar none. That means a lot. I appreciate that. Yeah, part of the reason I love these streams is because you guys are, like, really engaged. And, like, I mean, you guys are encouraging a lot, too. Like, it's awesome. Like, thank you so much for the kind words.

[02:19:09 - 02:19:11]  Like I don't take that lightly.

[02:19:11 - 02:19:13]  So yeah, and I'll keep it up.

[02:19:13 - 02:19:16]  Like everything I'm doing, I just want to keep improving myself

[02:19:16 - 02:19:18]  for you guys, like more and more every single day

[02:19:18 - 02:19:20]  in the way that I'm presenting and the systems

[02:19:20 - 02:19:24]  that I'm building and the content that I'm curating every day.

[02:19:27 - 02:19:30]  Yes, you're very welcome to you.

[02:19:30 - 02:19:31]  Appreciate that.

[02:19:33 - 02:20:27]  Could SuperData pull menu items from a restaurant website? Or would you use another web scraper? That's a good question, JP. So SuperData is more specifically for social content. If I go to their main website here. So yeah, like YouTube, TikTok, Instagram, X. If you want something more for web scraping in general, I would highly recommend crawl for AI. Also, crawl for AI is free, unlike SuperBbase. So it's not as robust for something like YouTube transcripts, but for crawling general websites. Crawl for AI is fantastic. And there's also a couple of videos that I've done on Crawl for AI. If I go to literally on my second most popular video ever, I'll post this in the chat quick for you. You know, I'll title this is a crawl for AI intro. It's a little bit of an old video, so they've changed some things at their library but you'll still get the

[02:20:27 - 02:20:32]  general gist of how to use crawl for AI so you run it on your own computer he uses the headless

[02:20:32 - 02:20:36]  browser to crawl any site that you give the URL for so you can pull the content in markdown

[02:20:36 - 02:20:40]  which markdown is like the perfect format to feed into LLMs or to ingest in a knowledge base for

[02:20:40 - 02:20:54]  reg like what we're doing in this video or in this live stream not a video so yeah all right Cool.

[02:20:54 - 02:20:56]  Cool.

[02:20:57 - 02:20:57]  All right.

[02:21:00 - 02:21:00]  Let's see where we're at with the plan here.

[02:21:01 - 02:21:02]  Okay, so plan is done.

[02:21:05 - 02:21:07]  And I'm going to go really fast through this here and then implement it.

[02:21:07 - 02:21:11]  So, okay, this time, our markdown.

[02:21:13 - 02:21:14]  Wait.

[02:21:17 - 02:21:44]  Are you guys seeing this? It just generated a 2,500 line markdown document. That is terrible. I told it to do 500 to 1,000. That is insane. I have never, I have never had this happen before, even if I didn't specify a limit, a line limit.

[02:21:44 - 02:21:48]  Like, I don't know what is going on here.

[02:21:48 - 02:21:50]  This needs to be,

[02:21:52 - 02:22:00]  wow, that, why in the world is this 2,500 lines long?

[02:22:00 - 02:22:01]  That is actually insane.

[02:22:03 - 02:22:05]  I've never had this happen before.

[02:22:05 - 02:22:08]  There's, I think it's, well, it's like,

[02:22:08 - 02:22:11]  there's something else that's kind of like Murphy's law, but like for live streams,

[02:22:12 - 02:22:15]  like if something can go wrong, it's going to go wrong in a live demo.

[02:22:16 - 02:22:21]  And Claude Sond at 4.5, deciding to completely ignore my instruction,

[02:22:22 - 02:22:24]  is, yeah, that is crazy.

[02:22:24 - 02:22:28]  I've used this exact prompt before.

[02:22:28 - 02:22:32]  I know this is like a more simple version of what I used for my planning command.

[02:22:32 - 02:22:37]  I've used this exact thing before a dozen times, even though it's the simple version.

[02:22:38 - 02:22:41]  And I haven't specified how long to make it before, like I am now.

[02:22:41 - 02:22:44]  Like I did it in the command, and then I also did it explicitly in the prompt,

[02:22:44 - 02:22:46]  because I didn't restart Claude Code.

[02:22:46 - 02:22:48]  I've never had to do this before.

[02:22:49 - 02:22:53]  And the agent that it's building here is basic.

[02:22:53 - 02:22:55]  There's two tools that I'm giving it.

[02:22:56 - 02:22:57]  That is nuts.

[02:23:00 - 02:23:03]  That is so crazy.

[02:23:05 - 02:23:05]  Repeat at top bottom in all cats.

[02:23:07 - 02:23:07]  Yeah, I might have to.

[02:23:10 - 02:23:10]  Whoa, I'm just going to ask it here, so we should be good.

[02:23:11 - 02:23:11]  That is, I mean, I'm just going to laugh at it.

[02:23:16 - 02:23:17]  Like, that's actually pretty frustrating, but it shouldn't take long to correct it,

[02:23:18 - 02:23:18]  and I'll just have it, make it concise here.

[02:23:19 - 02:23:20]  It's just, it's funny, like, whatever.

[02:23:22 - 02:23:23]  All right, Cod, you do what do you want to do.

[02:23:25 - 02:23:25]  Does Archon use crawl for AI natively?

[02:23:26 - 02:23:26]  Yes, it does.

[02:24:48 - 02:24:48]  Yeah, thanks for asking that, because I should have called that out right away when I was was recommending crawl for AI Arccon does actually use it so when you guys are running Arcon locally you are running crawl for AI locally and it's it's leveraging crawl for AI to crawl the documentation and Other knowledge that you're bringing into your Arcon knowledge base. Yep Maybe Claude just had a great need to communicate today apparently yeah. I mean for some reason, Claude, like, well, really this, oh, wow, it made it really short. That's kind of uncomfortable. See, look at the, what the heck? I said 500 to 1,000, and it doesn't, because now it's too short. That is insane. That is so weird. Yeah, okay, sorry, to your comment, Toby. I was going to say, like, these models, like, they act differently each day sometimes. It literally feels like there's something different. And it could actually be like there was an update to the system prompt for Claude between times that I've used this command. Like it honestly might be. And so it is kind of something where like you do have to constantly evolve your system to adapt to the tools that you're using. And that is one of the things that I'll be covering in the agentic coding course as well as how you can adapt your systems as better LLMs come out or LLM's change, like system prompts change in your tools, right?

[02:24:51 - 02:24:52]  Or like you have a, just like a new tool that you're using.

[02:24:53 - 02:24:54]  So, yeah.

[02:24:55 - 02:24:55]  All right.

[02:24:57 - 02:25:01]  So we're excluding all this stuff.

[02:25:06 - 02:25:10]  Yeah, because I don't know if it's referencing the examples as much as I need it to anymore.

[02:25:11 - 02:25:11]  You know what?

[02:26:07 - 02:26:17]  I'm going to just go for it. I'm gonna just implement this because I'm running out of time here. So slash execute plan, PRPs, requests, YouTube, or AI, coach, agent. This is actually kind of a nice test. It's not ideal, but it's kind of cool for this live stream to be able to show, like here's what happens when your plan is way too long, and then here's what happens when it's a little bit short. I'm curious, I think it might actually be able to knock things out even with a simpler plan of attack here. Because in the end, simple is always better than over-engineered. This is too short to my liking, probably. Because I think that if I had a bit more text, I would be able to reduce some more of the assumptions the coding assistant has to make during implementation. But I still think this is going to be way better than having a 2000 liner, because then it's not going to miss stuff, right? Like it's going to knock out these tasks one by one in Arcon's it's going to do a good job so yeah let's uh watch these populate in real time here go back over to arcon youtube a i coach agent all right so it's going to

[02:26:17 - 02:26:25]  create all these in parallel here so we'll see them all pop up in a sec try it with gpt5

[02:26:25 - 02:26:35]  codex again frankie says yeah you know what this live stream is making me want to try codex again I'm not gonna lie yeah because

[02:26:35 - 02:26:40]  this has been frustrating in the end it's fine like we got the rag pipeline to work

[02:26:40 - 02:26:44]  it's not ideal yet and I'll probably have to do some work to incorporate

[02:26:44 - 02:26:49]  dockling correctly and all of that but I mean it's it's working well but yeah I

[02:26:49 - 02:26:53]  mean like what the heck I don't know why it's so stupid in the planning phase

[02:26:53 - 02:26:56]  usually the planning phase is the simple phase.

[02:26:57 - 02:26:58]  So I don't know.

[02:26:59 - 02:27:00]  I do want to try Codex again.

[02:27:01 - 02:27:01]  But okay, here we go.

[02:27:02 - 02:27:03]  We got all our tasks in Arcon now.

[02:27:04 - 02:27:04]  Well, it's creating some of them.

[02:27:05 - 02:27:05]  Yeah, there we go.

[02:27:06 - 02:27:10]  Okay, so they're coming in one by one.

[02:27:11 - 02:27:11]  Really, Belgium on your short?

[02:27:14 - 02:27:15]  Well, yeah, there's a lot of people in Dynamists in Belgium specifically.

[02:27:20 - 02:27:20]  Yeah, I don't know if it's like, I think it is top 10 for countries.

[02:27:21 - 02:27:48]  Pretty sure. Yeah. Claude is quite chatty. Yep, it is. I know. But I tried to be explicit. Like, you have to be short and it still wasn't. Usually that is all you need to do. So, um, does anyone else notice a slightly different persona with each chat? It does kind of mimic your own prompting.

[02:27:49 - 02:27:50]  Like, this is really funny, but if you, like,

[02:27:51 - 02:27:52]  include swear words into your prompts,

[02:27:54 - 02:27:54]  you know, like you drop a nef bomb a couple times,

[02:27:56 - 02:27:57]  it'll actually start to do it itself.

[02:27:59 - 02:27:59]  So if you're curious, you could try it.

[02:28:00 - 02:28:00]  I mean, I don't really want to try it right now,

[02:28:03 - 02:28:03]  but yeah, so that might be why.

[02:28:04 - 02:28:04]  If you're just talking to it in a different way,

[02:28:07 - 02:28:08]  it kind of emulates that, even if it's, like, really subtle things.

[02:28:09 - 02:28:10]  Otherwise, though, it does depend,

[02:28:12 - 02:28:15]  like if Claude Codex updates the system prompt, or like Codex updates the system prompt under the hood that'll change its

[02:28:15 - 02:28:21]  persona as well yeah using sonnet 4.5 is generating mistake after mistake

[02:28:21 - 02:28:27]  it's like overloaded yeah that is kind of like a really real problem that people

[02:28:27 - 02:28:32]  and I honestly myself right now is facing is these models like they seem to vary

[02:28:32 - 02:28:36]  in performance and like these providers like anthropic and open AI they promise

[02:28:36 - 02:28:42]  it's not happening like we're not quantizing our models we're not doing extra rate limiting for different users and things like

[02:28:42 - 02:28:46]  that but it really feels like it's happening like i don't know i don't trust it entirely

[02:28:47 - 02:28:56]  so i think you're on to something yeah richard gets it to swear a lot it's funny yeah i know some people

[02:28:56 - 02:29:01]  that make it does well it's funny when it does but yeah okay so we're ripping through the

[02:29:01 - 02:29:06]  implementation now so the plan is um i'm going to let the implementation rip,

[02:29:06 - 02:29:08]  and then we'll test it,

[02:29:08 - 02:29:09]  and then we will call the stream there,

[02:29:09 - 02:29:12]  because I am losing my voice a little bit.

[02:29:13 - 02:29:14]  Yeah, but for those of you guys

[02:29:14 - 02:29:16]  who've stuck around for this entire stream,

[02:29:16 - 02:29:17]  and then we've still got more to come,

[02:29:17 - 02:29:19]  like I wanna see this in action.

[02:29:19 - 02:29:20]  I think you guys should hold out for the end,

[02:29:20 - 02:29:22]  we'll see it in action, but I was just gonna say that,

[02:29:22 - 02:29:26]  like, this is like been a long stream,

[02:29:26 - 02:29:29]  and I appreciate all you guys for sticking around

[02:29:29 - 02:29:31]  and hanging out with me here,

[02:29:31 - 02:29:34]  watching me build this agent. i want to keep building this out for the

[02:29:34 - 02:29:40]  channel not just has this use case for the live stream but really to make this something incredible

[02:29:40 - 02:29:44]  for all of my youtube content you can go here and like ask questions like how do i

[02:29:44 - 02:29:49]  incorporate this into my code base or like how do i build an agent that is similar to how cool built

[02:29:49 - 02:29:55]  xyz right like being able to ask those questions and have it guide you i think will be a like a really

[02:29:55 - 02:30:00]  phenomenal resource and then maybe like even in the dynamis community, making this agent like be able to

[02:30:00 - 02:30:03]  reference my course material as well, like for the people that are in Dynamis.

[02:30:04 - 02:30:05]  That would be super cool.

[02:30:05 - 02:30:09]  So yet another reason to come join the community because I want to build this agent into the

[02:30:09 - 02:30:11]  community as well for the things that we got there.

[02:30:12 - 02:30:16]  So that like someone in the Dynamis community could like come into this agent and ask

[02:30:16 - 02:30:21]  questions and it would reference both my YouTube transcripts and the agent decoding

[02:30:21 - 02:30:26]  course transcripts and the AI agent mastery course transcripts and the workshop transcripts

[02:30:26 - 02:30:31]  like imagine that like that would be such a powerful agent and it's a little bit

[02:30:31 - 02:30:37]  sloppy building the foundation right now but that is what I'm doing yeah so it'd be

[02:30:37 - 02:30:40]  pretty cool I'll probably have to go back and improve some things with better

[02:30:40 - 02:30:45]  planning off stream but I just wanted to show you guys what it looked like as much

[02:30:45 - 02:30:51]  as I could realistically in a stream yeah you're welcome, Toby.

[02:30:51 - 02:30:52]  I appreciate it.

[02:30:52 - 02:30:54]  Yeah, you're welcome as well, Tony.

[02:30:54 - 02:30:56]  Is this going to be a weekly live stream?

[02:30:56 - 02:30:58]  I'm not planning on doing live streams on YouTube weekly.

[02:30:58 - 02:31:00]  I want to do them monthly though.

[02:31:00 - 02:31:04]  Because what I do in the Dynamist community is weekly live streams essentially.

[02:31:04 - 02:31:07]  When I do the Friday workshops, like every single Friday.

[02:31:07 - 02:31:12]  I have done a live event every Friday since April.

[02:31:12 - 02:31:43]  And that is kind of like the weekly stream basically. So yeah, but like still want to do a ton on YouTube as well. Yeah Frankie doesn't trust him either. The difference in the results are sometimes too great for the same question. Yeah 100%. Raymond said I've noticed that or here let me highlight these again. I've noticed that based on the time of day effort that the AI puts into the work varies. Yep it feels like when the batch processing begins to geted, its token effort is adjusted.

[02:31:43 - 02:31:47]  Yes, it does, and they say they don't do it.

[02:31:47 - 02:31:50]  But I really think you're right, I do.

[02:31:50 - 02:31:52]  It's unfortunate.

[02:31:52 - 02:31:54]  Like, I get why they have to,

[02:31:54 - 02:31:57]  because a lot of these companies are spending more money

[02:31:57 - 02:31:59]  they're making, because they're just trying to,

[02:31:59 - 02:32:02]  you know, get the next round of funding,

[02:32:02 - 02:32:06]  you know, get as much of the market as they can.

[02:32:06 - 02:32:07]  And almost, you know, like creating a monopoly

[02:32:07 - 02:32:09]  and then jacking up prices, right?

[02:32:09 - 02:32:12]  Like, kind of like what Nvidia has done in the past.

[02:32:12 - 02:32:15]  So it's like losing money now in the hopes of like getting the market

[02:32:15 - 02:32:17]  and then just like forcing prices on them later.

[02:32:17 - 02:32:19]  I don't want to be all doom and glue.

[02:32:19 - 02:32:21]  And I'm not saying that like is exactly what's happening for sure.

[02:32:22 - 02:32:24]  But I think that's like a viable theory.

[02:32:24 - 02:32:25]  I'll just leave it at that.

[02:32:25 - 02:32:28]  Like I'm not trying to get super opinionated or political or anything.

[02:32:28 - 02:32:30]  But I think it is an interesting conversation.

[02:32:32 - 02:32:33]  Definitely worth considering.

[02:32:33 - 02:33:02]  Like just watching out for that as you're coding, like it is kind of crazy that my Create Plan command that I have here that's worked so well for me before has just led to these, like, kind of poor planning documents today. And the documents were good. Like, it followed the steps here. It was just specifically the length, which it kind of feels like it's just like a big problem with Claw that would just happen to be amplified today honestly is what it feels like

[02:33:04 - 02:33:12]  yeah loss leader yep yep thank you so much the initial plan has created a very nice uv run

[02:33:12 - 02:33:17]  rag pipeline with dockling feel quite powered up right now with your instructions and guidance

[02:33:17 - 02:33:21]  that's cool i appreciate you following along and building like that that's that's really cool

[02:33:21 - 02:33:52]  so i'm glad that you have created something awesome sweet and I never expect people to follow along because I know that it's a lot just to like digest what we got going on here, but that's super cool that you did and that you built something fantastic. So congrats. Seems like your coding assistant didn't ignore a dockling like it did for me, so kudos to you. I wish mine used dockling, but I'll make it later. Don't worry. All right. Cool, I appreciate that.

[02:33:52 - 02:34:25]  It's been an incredible stream. Seeing this build bit by bit makes us feel a part of the process. Can't ask for anything more. That means a lot. I'm glad that you guys are liking it, even considering how it's, yeah, just it takes time to go through this process, and there's a reason why my YouTube videos don't cover certain things just to make it more concise. So I'm glad you guys are liking that. Yeah, and why you stopped using BMAD? I haven't actually stopped using BMAD. I just, I don't use it a lot, I would say, but I am going to cover it in the agentic coding course as one of those primary options for like an out-of-the-box solution for an AI coding system.

[02:34:26 - 02:34:36]  The one thing I will say on the B-Mad method, and honestly a lot of different strategies for context engineering, is I think that they are very prone to over-engineering.

[02:34:36 - 02:34:41]  Because when you have so many steps in a process, like here are all the different sub-agents.

[02:34:41 - 02:34:46]  And like each one of these sub-agents is contributing some work or like some planning to the project.

[02:34:46 - 02:34:50]  It just leads a lot of times to more getting done than actually needs to get done.

[02:34:50 - 02:34:52]  I think that would be my main critique for something like B-Mad.

[02:34:52 - 02:34:56]  I'm not saying it, I still do think it's a great framework.

[02:34:56 - 02:34:59]  And the guy who created is like seriously a genius.

[02:34:59 - 02:35:02]  The ideas are really solid and profound in some ways.

[02:35:02 - 02:35:04]  But you just have to be careful.

[02:35:04 - 02:35:14]  Some of the issues of Claude over-engineering are just amplified if you're not careful how you use them I would say so yeah like I had a 2,000 line

[02:35:14 - 02:35:18]  plan created the first time I used B-Mad right like just like what happened here but

[02:35:18 - 02:35:21]  like here I'm using a process that I know like generally doesn't do that right

[02:35:21 - 02:35:27]  and like B-Mad might not either but yeah it happens you have to be careful so yeah

[02:35:27 - 02:35:33]  all right let's um oops let me to highlight that one again and go back over to

[02:35:33 - 02:35:41]  Arcon and see where we're at. Just do a refresh here. All right. Cool. So we got 10 in review and we are

[02:35:41 - 02:35:49]  basically to the testing phase now. Okay, so here's what I'm going to do. Be very fast with

[02:35:49 - 02:35:55]  the testing. I just, I want to get to the point where I can validate things with you guys here.

[02:35:55 - 02:35:59]  So I know it's a little silly, but I'm just going to ask it to blitz through the testing here.

[02:36:01 - 02:36:03]  So let me take a look at the agent.

[02:36:03 - 02:36:04]  So we got agent.

[02:36:04 - 02:36:09]  We got our system prompt, which this is probably one of those things I would iterate on a lot

[02:36:09 - 02:36:15]  before I just deploy this to production, but it looks pretty good overall.

[02:36:15 - 02:36:20]  I like how it even has like an example interaction in the system prompt.

[02:36:20 - 02:36:21]  That's pretty neat.

[02:36:21 - 02:36:23]  So we define our agent, that looks good.

[02:36:23 - 02:37:21]  We have our RAG tool, and then we have our Gitful transcript tool, and it's just calling a single function that we're importing from our tools folder here. So, yep, looks really good. We got our service where we, yeah, okay. So again, really fast, really high level, but this is looking great. So looking good. The other thing I wanna look at was the API endpoint. So we have our main dot pi where we are, yeah, building our API, very similarly to how we did in the example. So it really does seem like the more concise plan did a much better job. It's not skipping through anything that I can tell here. And that dockling thing I picked out almost immediately. So I've worked that muscle over time for how to validate things really quickly with AI coding assistance. So I found that it was missing dockling right away. Looking at this initially, at least, and in a realistic setting, I would want to dive a lot more deep into this. But like right now, it doesn't seem like it's missing stuff.

[02:37:21 - 02:37:23]  This API endpoint looks really solid.

[02:37:23 - 02:37:26]  And so it's running Pidentic Agent endpoint.

[02:37:29 - 02:37:31]  Yeah, this looks really good.

[02:37:33 - 02:37:34]  This is kind of weird.

[02:37:34 - 02:37:38]  Okay, well, I'll, yeah, having imports at the bottom is stupid.

[02:37:39 - 02:37:41]  Maybe I'll move this quick.

[02:37:41 - 02:37:45]  So that seems like a bit of a iffy thing,

[02:37:45 - 02:37:48]  but I'll ignore that for now.

[02:37:48 - 02:37:50]  Those little smells like that you, like code smells

[02:37:50 - 02:37:52]  that you wanna look out for.

[02:37:52 - 02:37:55]  But let me see how I start the agent now.

[02:37:58 - 02:38:00]  I guess I have to do setup guide.

[02:38:03 - 02:38:03]  Okay.

[02:38:05 - 02:38:09]  Configure environment variables,

[02:38:09 - 02:38:38]  verify installation, run the pipeline. Okay, so it hasn't done documentation for the agent yet so this is just everything for the rag pipeline right now so that's fine um what i want to do okay good it created the tables for nice okay yep okay so i'll run the table creation here so i'm just trying to like do as much in parallel as i can to get this to be quick um create a new snippet So I'll create all the tables

[02:38:38 - 02:38:42]  that told me to create for the RAG agent.

[02:38:44 - 02:38:46]  Okay, there we go.

[02:38:46 - 02:38:49]  Channels, conversations, messages, requests, looks good.

[02:38:50 - 02:38:51]  Nice. All right.

[02:38:54 - 02:38:59]  And then, let me go back to the coding assistant here.

[02:39:00 - 02:39:01]  How far is it?

[02:39:01 - 02:39:02]  Okay, so it's running the validation,

[02:39:02 - 02:39:08]  which I really hope this doesn't take that long make sure you update the

[02:39:08 - 02:39:14]  read-me-after with instructions on how to run the agent and how to specify the port

[02:39:14 - 02:39:19]  the agent runs on all right I just want to make sure it does that as well I think it

[02:39:19 - 02:39:24]  already has it as a task to update the documentation but well yeah all right that's

[02:39:24 - 02:39:27]  fine it already has it but I'm just making sure it's explicit in doing that here

[02:39:27 - 02:39:31]  so okay yeah things are looking a lot better.

[02:39:31 - 02:39:35]  This shorter plan definitely made a difference, which is very cool.

[02:39:38 - 02:39:49]  All right, so yeah, as a validator is going here, I think this is the last time that I want to talk about the agentic coding course really quickly.

[02:39:50 - 02:40:26]  Because this is like very, we're almost done with the stream here, and this is the last call for the discount for the dynamic community. So I'm going to pop it up one more time, one last time. We've got to do it. Because the course, first batch, just came out on Friday. And we're going to be doing this live, like workshops at the end of every release batch, kind of coming in as like the first cohort for all of us together to master building, reliable, and repeatable systems for working with AI coding assistance. And yeah, let me pop up the page one more time here so in joining the dynamist community like you get like this course

[02:40:26 - 02:40:32]  is a part of the community included directly and it is all about building reliable and repeatable

[02:40:32 - 02:40:37]  systems to get the most out of AI coding assistance this you're not going to learn this anywhere else

[02:40:37 - 02:40:41]  especially not like with a community of support coming alongside you as one like I'm here every

[02:40:41 - 02:40:47]  single day to not just like help you go through the course but also to answer any questions as you

[02:40:47 - 02:40:48]  build your own system.

[02:40:48 - 02:40:50]  That's optimized for your code base.

[02:40:50 - 02:40:51]  Like that's the system, yeah,

[02:40:51 - 02:40:54]  that's what I help you through in the course

[02:40:54 - 02:40:57]  and the primary goal.

[02:40:57 - 02:40:59]  Like this is one other thing

[02:40:59 - 02:41:01]  that I haven't talked about in this live stream yet.

[02:41:01 - 02:41:04]  I think that you guys will find it really interesting.

[02:41:04 - 02:41:07]  The main mental model that I have in the course

[02:41:07 - 02:41:10]  is that every mistake is an opportunity

[02:41:10 - 02:41:11]  to evolve your system.

[02:41:11 - 02:41:43]  It's kind of like what I did when the plan that was created here was way too long. Like I went in, and this is like a really basic example, obviously, but like I made an addition to my prompt. This is like, you know, kind of part of my system. It's a very simple system, but it's a part of my system. I saw a mistake and I corrected it. And now every time going forward, I have this, you know, very slightly evolved version of my system. And that's like the main mental model that I have for you. So when we see a mistake with the AI

[02:41:43 - 02:41:50]  coding assistant, instead of doing a one-off fix, we fix the system and then we retry. Right. And like,

[02:41:50 - 02:41:55]  that's the high leverage skill that I show you how to develop in the course, making every

[02:41:55 - 02:42:01]  mistake an opportunity. And really like that is your competitive advantage. Right. And so like that's,

[02:42:01 - 02:42:05]  that's the main thing that I'm covering here. And along with everything else that you get in the

[02:42:05 - 02:42:32]  Dynum's community, like even the agenta coding course itself i've designed it to be well worth your investment in the community every single month or you know every year if you go with that route so yeah 20% off with the code that's going to expire after the live stream for the monthly membership and then 40% off the annual so jump on it now like i'm taking it down like right after a live stream so this is your chance here and if you're already in the dynamist community then like go at it right now, this is available for you.

[02:42:32 - 02:42:32]  It's super exciting.

[02:42:33 - 02:42:35]  I'm here to answer any questions as you go through it as well.

[02:42:36 - 02:42:36]  So, yeah.

[02:42:37 - 02:42:38]  All right.

[02:42:41 - 02:42:43]  Let's call it at closing time.

[02:42:43 - 02:42:43]  Yeah.

[02:42:45 - 02:42:48]  Man, your live streams are always instructive and entertaining.

[02:42:48 - 02:42:49]  Love to be a part of the Dynamist community.

[02:42:49 - 02:42:51]  Highly recommend anyone interested in developing AI to join.

[02:42:51 - 02:42:52]  Keep the great job.

[02:42:52 - 02:42:53]  I appreciate a lot.

[02:42:54 - 02:42:54]  Mr. Navado.

[02:42:54 - 02:42:55]  Thank you very much.

[02:42:57 - 02:42:58]  Cool.

[02:43:01 - 02:43:02]  It doesn't make sense to subject

[02:43:02 - 02:43:03]  Perplexity Pro.

[02:43:03 - 02:43:06]  Does it have any API utility like other models?

[02:43:06 - 02:43:08]  I do use Perplexity myself.

[02:43:08 - 02:43:10]  I use It plus OpenAI deep research.

[02:43:10 - 02:43:12]  Typically, like at the same time when I want to do

[02:43:12 - 02:43:14]  a lot of extensive research on something.

[02:43:14 - 02:43:16]  So I like perplexity.

[02:43:16 - 02:43:18]  I think that it's actually pretty impressive

[02:43:18 - 02:43:19]  that they've stood the test of time,

[02:43:19 - 02:43:21]  just as other tools have come out,

[02:43:21 - 02:43:25]  like Anthropics Deep Research and opening eyes deep research

[02:43:25 - 02:43:28]  and laying chains deep research and like there's still like I feel like it's very

[02:43:28 - 02:43:32]  really valuable especially the speed at which it is able to analyze sources and

[02:43:32 - 02:43:40]  things so I do like perplexity I'm in says Mark looking forward to learning

[02:43:40 - 02:43:44]  awesome mark welcome to Dynamis I appreciate it a lot unless you're saying

[02:43:44 - 02:43:47]  you're already in but I assume you mean that you're in now so welcome welcome

[02:43:47 - 02:43:51]  super excited to have you in.

[02:43:51 - 02:43:53]  Cool.

[02:43:55 - 02:43:56]  I don't know what Claude is doing here.

[02:43:58 - 02:44:00]  Wait, this is actually bonkers.

[02:44:02 - 02:44:04]  Okay, that was just a UI glitch. All of a sudden, it's just, I don't know,

[02:44:04 - 02:44:05]  do you guys see that?

[02:44:05 - 02:44:06]  It was just like validator.

[02:44:06 - 02:44:09]  It was like repeating over and over and over again.

[02:44:09 - 02:44:10]  That was like really weird.

[02:44:11 - 02:44:13]  Okay, but it like corrected itself.

[02:44:13 - 02:44:14]  It was just a UI thing.

[02:44:14 - 02:44:46]  It wasn't actually calling my validator a million times. That's good. Okay. Cool. Steven just joined. Welcome, Stephen. I appreciate it a lot. Cool. Glad to have you in. Appreciate it, Aunt Chanton. Thank you. Gemini is amazing at deep research. Yeah, 100%. Mr. Nemando and Mark, looking forward to learning with all of you. Cool, cool. Welcome as well just use reflexity MCP tool and a workspace directive to

[02:44:46 - 02:44:50]  consult perplexing all problems that require more than one attempt nice

[02:44:50 - 02:45:03]  that's that's smart I like that cool all right okay let's see here

[02:45:03 - 02:45:36]  Korean said it is the 80% 20% rule B-Mad shows you the rest of the 80% 20% rule. BMAD shows you the rest of the 80% up front when you have an MCP at 20% of the effort, just the happy path. Maybe you could elaborate a bit more in what you're getting at. I think what you're saying is that B-MAD, it gets you 80% of the way there, but then it's up to you with your process and your tooling to finish, which I would agree with that. Maybe that's not exactly what you're saying. But yeah, a lot of these frameworks, like PRP and B-MAD, like, they're not meant to fully replace whatever kind of process you have for using AI coding assistance but they do

[02:45:36 - 02:45:48]  augment right it's just another thing in your tool belt to augment your process right so yeah okay so

[02:45:48 - 02:45:53]  we're updating the read-me here I think I will have to set my okay I'll have to set my

[02:45:53 - 02:46:04]  environment variables so I will do that off camera really quick here because i just have to yeah so i have to configure things for the ai agent

[02:46:06 - 02:46:11]  let me do that really fast i'll i'll just use gpt 4.1 mini for my model right now

[02:46:11 - 02:46:20]  i'll just keep it simple all right API port 8040 right that's what i have running in docker

[02:46:21 - 02:46:30]  i'm gonna try i'm gonna try my best to get a demo for you guys working right before I close the stream here and then I'll upload everything to GitHub later as well

[02:46:32 - 02:46:33]  API is running on

[02:46:33 - 02:46:40]  8,001 okay let me correct that so I'm gonna close the API that I have running

[02:46:41 - 02:46:49]  in my Dynamous agent already because I'm gonna spin it up with the code we just created and fingers crossed it nails it

[02:46:50 - 02:46:53]  we'll see, okay.

[02:46:56 - 02:46:56]  And if it fails right now, I probably won't iterate that much,

[02:46:58 - 02:46:58]  because I'm about to lose my voice.

[02:46:59 - 02:47:01]  But this has been a blast.

[02:47:03 - 02:47:03]  Oh, you reached a super data rate limit.

[02:47:04 - 02:47:04]  Yeah, that'll happen.

[02:47:07 - 02:47:09]  Yeah, you probably don't want to pull like a million videos within a minute or an hour or whatever it is.

[02:47:11 - 02:47:12]  Okay, let me go.

[02:47:12 - 02:47:14]  Okay, so we updated documentation.

[02:47:17 - 02:47:21]  And then run the AI coach.

[02:47:23 - 02:47:24]  Okay.

[02:47:25 - 02:47:27]  Okay, the instructions are a little jank,

[02:47:27 - 02:47:29]  but this is gonna work.

[02:47:29 - 02:47:31]  So we're good, all right, run this,

[02:47:31 - 02:47:34]  and I wanna run on port 8,001.

[02:47:36 - 02:47:40]  And I don't know why, why is the host,

[02:47:41 - 02:47:44]  well, I'll try this. I'll just try this.

[02:47:44 - 02:47:47]  Okay.

[02:47:48 - 02:47:49]  We got an error right away.

[02:47:52 - 02:47:55]  Okay, so I'm going to try to iterate a couple of times. So why is the host 0.0.0.0.

[02:47:55 - 02:47:58]  Shouldn't it be local host unless I'm running in a container?

[02:47:58 - 02:47:59]  So I'm not running in a container right now.

[02:48:00 - 02:48:02]  And then also I got this attribute app not found in the module error.

[02:48:03 - 02:48:04]  So address this as well.

[02:48:05 - 02:48:05]  Okay.

[02:48:06 - 02:48:07]  Cool.

[02:48:07 - 02:48:09]  Because it doesn't seem like a drastic issue, right?

[02:48:09 - 02:48:12]  So like I shouldn't have to go through the PIV loop again so

[02:48:12 - 02:48:18]  send in the error ask it to think through and find the implementation or find the fix and then just

[02:48:18 - 02:48:22]  let me know what went wrong like that's my standard process for working with these little problems

[02:48:22 - 02:48:26]  hopefully it's a little problem I don't know exactly I'm not taking the time to dive into it

[02:48:26 - 02:48:31]  right now but hopefully it is a smaller problem so let me restart this

[02:48:33 - 02:48:38]  oh it's being stupid it won't let me close out of it. There we go. All right. I'll be ready to run it again

[02:48:38 - 02:48:54]  once it corrects itself here. Okay. Looks good. Yeah, Raymond, that is true. For some reason,

[02:48:54 - 02:49:04]  though, whenever I, when I have it run on Oda, oda, oh, dot, oh, oh, oh. So, and if it's not in a container, like, sometimes it, like, a local host connection won't work. Maybe I was doing

[02:49:04 - 02:49:11]  something wrong and I just, like, messed up my own knowledge previously. I don't know. I think

[02:49:11 - 02:49:19]  this will be fine, so I'll try this. You're probably right, though. I'll just run this.

[02:49:19 - 02:49:55]  I think this will be good. Okay, come here. There we go. I'll just delete this and re-enter it. 801. Oh, thank you for the $10 donation. I appreciate it a lot. Thanks for all your videos here. Very helpful. You are quite welcome. And also, I think I missed a donation earlier from Dax. I think, like, at the start of the stream, I just, like, that triggered my memory. I'm really sorry, Dax, I missed yours. So thank you as well if you're still here

[02:49:55 - 02:49:57]  for your $10 donation.

[02:49:57 - 02:49:59]  And yeah, for the one right now, I appreciate it a lot.

[02:49:59 - 02:50:00]  That means a lot.

[02:50:00 - 02:50:01]  Thank you for your support.

[02:50:01 - 02:50:03]  And yeah, let's, I'll do it for you.

[02:50:03 - 02:50:05]  Let's see if the API endpoint works for you.

[02:50:05 - 02:50:07]  Okay, looks good.

[02:50:07 - 02:50:09]  Cool.

[02:50:10 - 02:50:12]  So a moment of truth.

[02:50:14 - 02:50:17]  Well, hold on, I have to restart my other agent though.

[02:50:21 - 02:50:24]  Yeah, let me do that quick.

[02:50:26 - 02:50:29]  Or maybe I'll just start the front end.

[02:50:29 - 02:50:29]  Yeah, hold on.

[02:50:33 - 02:50:35]  I got to do this off camera, but I'm going to set it up so that I can run my agent.

[02:50:38 - 02:50:45]  8,001 API, Panic Agent.

[02:50:47 - 02:50:50]  So I have to set up environment variable. Well actually I don't have to do this off camera because it's a front end.

[02:50:50 - 02:50:52]  So these aren't actually secret.

[02:50:52 - 02:50:55]  So I'm going to go back to my Supa base here.

[02:50:55 - 02:50:59]  And I'm going to grab my Anonymous Key.

[02:50:59 - 02:51:02]  And I'm going to paste this in here.

[02:51:02 - 02:51:05]  I mean, this looks kind of messy, but I don't care.

[02:51:05 - 02:51:07]  All right, Anonymous Key.

[02:51:07 - 02:51:42]  Then go back and get my project URL. Nice. And then I'll open up a new terminal here. So I'm starting my front end, which my front end is something that I've already built. So I'm not like showing how I built my front end from scratch here. But it's running on port 8080, and I have it connecting to the agent on local hosts, 8,001 API slash Panantic agent, which aligns with the port that I have it running with the code that we just built together right now, Port 8,001.

[02:51:43 - 02:51:49]  I have absolutely zero guarantee that this is going to work right now, but that would actually be insane if it worked.

[02:51:49 - 02:51:50]  Let's try this.

[02:51:52 - 02:51:57]  So I have to remember, I think I use like a throwaway email for this.

[02:51:59 - 02:52:00]  Oh, man.

[02:52:01 - 02:53:02]  I don't remember the login information oh it worked okay okay here we go moment of truth I'm in my chat interface I'm signed in I'm gonna send a message I'm gonna see what happens I'm gonna just say hi okay oh it's just the user's not present in okay okay so that's fine I forgot to create my user in the user table so So when a user first signs up for the platform, it automatically creates this record, but I made this table after. So that's why I'm getting this. I'll see. Boom, boom, and I am an admin. Yes, OK, save. Good. Reload. Hello. Look at that. OK. It actually worked. now the real test is the rag tools here but okay let's just take a second and

[02:53:02 - 02:53:10]  appreciate that this actually worked I told it to reference this API file like copy the exact

[02:53:10 - 02:53:14]  API endpoint to work with this front end and it actually did like this agent is working in the

[02:53:14 - 02:53:19]  front end like we can see that these are the logs that we got from the agent that we just built

[02:53:19 - 02:53:27]  right now that is super cool so now what I can say is like, oh, I don't even know. Like, search the

[02:53:27 - 02:53:40]  knowledge base for, someone give me a good question. For like what I could ask it based on one

[02:53:40 - 02:53:46]  of my recent YouTube videos. Like someone throw out something. Search the knowledge base for

[02:53:46 - 02:53:48]  whatever. Like I'm going to ask it some question here. I just want some example, like I'm gonna ask it some question here.

[02:53:48 - 02:53:50]  I just want some example, like from like my Dockling video

[02:53:50 - 02:53:52]  or like an Arcon video, trying to think.

[02:53:57 - 02:54:04]  Search knowledge base for the goals of Arcon.

[02:54:04 - 02:54:05]  I don't know, something like this.

[02:54:05 - 02:54:07]  What is, yeah, what is Arcon?

[02:54:07 - 02:54:08]  Thanks, Richard, that's good.

[02:54:08 - 02:54:10]  Search for what is Arcon.

[02:54:10 - 02:54:13]  Okay, this might fail.

[02:54:13 - 02:55:35]  There might be an error. We'll watch for an error here. Okay. That actually worked. So it used the RAG search and it embedded our query. Ooh. No way. Arcon appears to be a platform or tool related to AI or database management. Okay, that's kind of a dumb answer. But I think it actually... Yeah, so it's currently in beta with experimental features, ongoing development, run database migration. Okay, so the answer is not ideal, but that's probably just in the system prompt that I'd have to like tweak on like what it says. It uses super base for local data storage, which that's hilarious that it says super base instead of super base. And then it links to a video. Okay, here's the real moment of truth. If I open this video, is this actually going to be Rcon at a timestamp that is... Hey, look at that! It linked me to the beta launch live stream. Specifically to the Quick Start. Take a look at that. That is so cool. So it, okay, man, in the end, this worked beautifully. It took a little bit to get there. But wow, what a big payoff. Like, it actually worked. Okay, definitely problems that we have to address here. This is a really awkward answer, right? Like, I'm not going to try to say that, like,

[02:55:35 - 02:55:39]  this is perfect. But it cited its source, the link that I can click on that brought me right

[02:55:39 - 02:55:45]  to the video. It clearly understands everything from the transcript. There's some misspellings here.

[02:55:45 - 02:55:50]  Maybe we want to, like, integrate some strategy in the rag pipeline, would like analyze the chunks

[02:55:50 - 02:55:54]  to fix misspellings. We probably want to adjust the system prompt, so the answers are less

[02:55:54 - 02:57:18]  awkward. Like, quite a few things that we can correct here, but like this is a really solid proof of concept. And we actually did it. We got the big payoff and we did it live. I didn't know if I was gonna be able to do this. Three hours is a lot, like my voice is hoarse now, but like this was so worth it. It's so cool. Let's ask another question. Let's say search for a dockling hybrid chunking and link me to the part of the dockckling video where I talk about that. Let's try it, let's try another one here. All right, and this is like blazing fast, like holy cow, okay, at this point, discussion, rag strategies, okay, all right, is this dockling? Like, you're absolutely right, I apologize for it. Okay, so this answer is not ideal. I mean, it's still working, it pulled something, it just didn't pull it correctly here. If I wanted to really dig into this, that's when I had set up like agent of observability and like figure out the chunks that it pulled and everything and didn't find my dockling video. How about my video where I talk about dockling? The main topic of the video is dockling. Another thing that I should probably do is give the agent a tool to list out the videos that I have here. Like one thing that SuperData apparently didn't do correctly is it didn't pull the

[02:57:18 - 02:57:23]  titles or maybe that's something I have to fix in my RAG pipeline. So again, things are really

[02:57:23 - 02:57:27]  not perfect here. Like it probably can't actually find the exact video because of this.

[02:57:30 - 02:57:37]  Okay. Well, oh, it worked. Okay, cool. It found the video. Nice. Okay. So that's really good.

[02:57:37 - 02:58:37]  So now can I say, okay, search this video specifically for when I cover hybrid chunking. Now another thing that I haven't given this agent is the ability to limit its search to a specific video. I don't think it actually is going to be able to do that. Yeah, so like, oh no, okay, it actually did find it. Okay, so we're good. So it's like not perfect, but it's still kind of impressing me here, even given like how much I know I have to iterate on it. So yeah, this is the part of the video where I'm covering hybrid chunking. Like this is my example where I'm showing the output of the hybrid chunking script that I actually used as the example in our code base for today. So that's pretty cool. Awesome. Okay. That's enough of our testing here. And by the way, what I'm doing here, going back to our diagram, that is the manual testing part. Hold on. Let me go back. Okay, so what we're doing right here is the manual testing.

[02:58:37 - 02:58:37]  Right?

[02:58:38 - 02:58:39]  So like the code review I did very quickly,

[02:58:40 - 02:58:41]  the AI coding assistant took care of unit testing,

[02:58:42 - 02:58:42]  integration testing.

[02:58:42 - 02:58:44]  We're just doing the manual testing,

[02:58:44 - 02:58:45]  making sure things work.

[02:58:45 - 02:58:47]  And yeah, we found quite a few things to improve,

[02:58:48 - 02:58:49]  which that's fantastic.

[02:58:49 - 02:58:50]  We'll do that as I'll do that as well.

[02:58:50 - 02:58:52]  But like, man, we got a really good starting point.

[02:58:53 - 02:58:55]  So, all right, let's go.

[02:58:56 - 02:58:58]  Skipper Chunk, rocked it today, Cole.

[02:58:58 - 02:58:59]  Just joined in Dinus Community.

[02:58:59 - 02:59:01]  Looking forward to all your excellent content.

[02:59:01 - 02:59:08]  I appreciate a lot. Thank you very, very much. And welcome to Dynamis. Really excited to have you in.

[02:59:09 - 02:59:16]  Cool. And Craig, it is handling citations. If I go back, yeah, it's got the links right here with the timestamps and everything.

[02:59:17 - 02:59:21]  So yeah, we got our citations. Pretty sweet.

[02:59:23 - 02:59:39]  Nice one. Yeah, I appreciate it, Chad. Cool. All right, search for the most viewed video. I'll try. Search for my most viewed video. I don't think that I have that metadata, though. So I don't think it's going to be able to pull it.

[02:59:42 - 03:01:39]  Yeah, I don't think it has access to that, but we'll see. Yeah. Well, it's yeah, because it doesn't even understand that it's like a separate thing than a rag search. So it just tried to like search for that text in my transcripts. But that would be another cool thing to add 100%, Mattias, would be to add in the ability to like search metadata on videos as well. Like what's my most recent video? What's my most viewed video? What's my video that has the most likes or whatever it is? So yeah, there's so many more ways that I can expand this agent and I want to keep doing it. And it's actually freaking awesome that we got this far in only a few hours. And I didn't even do that much prep before the stream because I really wanted to build it from scratch with you guys and show what that looks like realistically. So this is super cool. Yeah. What are the three most important coding principles for AI coding? That's a good question. Maybe I'll actually end the stream with this question here. But one more thing I want to say after. So hold on, but I'll answer this here. So, yeah, I'd say the first one is avoid over engineering. I'm kind of like what we cover. Like I'm actually glad that that came up so much alive today. Avoid over engineering through the way that you're prompting and asking for simplicity and validating for simplicity. The second most important coding principle, well, actually, this is probably the most important is you want to have a system for working with your coding assistance. Like you want to define a process for, I mean, really everything that I cover in the PIV loop. Like with, you want your process for planning, your process for implementing, and your process for validating, and you want to create it in a way that's reusable, right? Like you have your rules, your global rules, you have your commands, you have your hooks, like whatever you want as like the package of what I like to call your AI layer, you want to define that in a way where you can use it for any project and create that as a reliable and repeatable system. And so never just like, like anytime you create a prompt two times, that's really similar.

[03:01:39 - 03:01:42]  That screams that you should turn it into a command and reuse it later.

[03:01:44 - 03:01:55]  And then the third principle that I would say, and like really, I mean, these are all principles that I've covered in this stream today, is that you should delegate as much code as possible to the AI coding assistant, right?

[03:01:56 - 03:01:59]  Like planning and validating is where you are in the loop.

[03:02:00 - 03:02:58]  That's where you want to inject yourself as much as possible, so you're not just vibe coding. But then, assuming you have a really well-structured plan that gives you the freedom to delegate all the code to the AI, and then you're just validating at the end, right? So delegate code. Really good question, though. Reference good example, says Beau. Yeah, referencing good examples like I did for our implementation today, clearly, because it works super well. The examples I had in here are coming directly from the Dynamist AI Agent Mastery course and the resources I have for you guys there. And so, yeah, that clearly worked well, giving it the ability to build that API endpoint perfectly first try, full conversation management, token streaming, message handling, everything in the database in the front end like first try. So super cool. But yeah, all right, I'm going to go ahead and wrap up the live stream here. So thank you again for everyone who was here, especially those of you guys who were here the whole time, like got a 170 people

[03:02:58 - 03:03:04]  on the stream here, which is an incredible number given how long this stream was and how much

[03:03:04 - 03:03:05]  I'm losing my voice right now.

[03:03:05 - 03:03:07]  But, yeah, it's fantastic.

[03:03:07 - 03:03:13]  So, yeah, last thing I'll say just as I wrap things up is, yeah, I'm going to have this discount

[03:03:13 - 03:03:17]  for the Dynamist membership up for just a tiny bit longer, and then I'm tearing it down.

[03:03:17 - 03:03:20]  And this really is something special for the live stream.

[03:03:20 - 03:03:22]  Because I really am doing this live stream,

[03:03:22 - 03:03:24]  this whole thing, building this agent with you

[03:03:24 - 03:03:26]  as a celebration of the first release batch

[03:03:26 - 03:03:29]  of the agentic coding course that's available

[03:03:29 - 03:03:30]  to everyone in Dynamis now.

[03:03:30 - 03:03:34]  So if this seems interesting to you, like, get in on this.

[03:03:34 - 03:03:37]  And 20% off monthly, 40% off yearly membership

[03:03:37 - 03:03:39]  for Dynamis right now for this course.

[03:03:39 - 03:03:41]  And I'm just gonna be pumping out more and more

[03:03:41 - 03:03:42]  for over the next month.

[03:03:42 - 03:03:45]  And then obviously more and more coming to Dynamis

[03:03:45 - 03:03:47]  well beyond this later as well. So yeah, even the course itself

[03:03:47 - 03:03:52]  I'm designed to be worth your investment in the community and just going so much deeper on all

[03:03:52 - 03:03:57]  these things that I covered in the stream today. And yeah, always we'll be doing things like this.

[03:03:57 - 03:04:04]  I always will be giving away so much on YouTube, but there's there's more special things in

[03:04:04 - 03:04:39]  Dynamis and the level that we go into there is unmatched for sure. So all right, sweet. This was fantastic, guys. So, yeah, thank you everyone again for being a part of this. And I'm super stoked that we have the agent working at the end. Like, that was so cool. Like, big payoff. We had it. And thank you, everyone, for your engagement, your questions as well. And with that, I will hopefully see a lot of you guys in the community. And I'll keep seeing you guys on YouTube. More content coming out next week around building AI agents.

[03:04:39 - 03:04:42]  I got a really interesting video on how to just keep things simple

[03:04:42 - 03:04:44]  when building agents for Wednesday.

[03:04:44 - 03:04:46]  So you guys will see that on Wednesday.

[03:04:46 - 03:04:47]  Hopefully you're looking forward to that.

[03:04:47 - 03:04:52]  So with that, hope you guys have a fantastic rest of your weekend.

[03:04:52 - 03:04:54]  And I will see you all later.